<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Rob Ashton's blog]]></title><description><![CDATA[Software development dumping ground]]></description><link>http://codeofrob.com</link><image><url>http://codeofrob.com/img/cover.jpg</url><title>Rob Ashton&apos;s blog</title><link>http://codeofrob.com</link></image><generator>NodeJS RSS Module</generator><lastBuildDate>Tue, 02 Apr 2013 10:29:08 GMT</lastBuildDate><atom:link href="http://feeds.feedburner.com/robashton" rel="self" type="application/rss+xml"/><item><title><![CDATA[Learning OMeta in Greece]]></title><description><![CDATA[<p>This week I'm in Athens (well, probably a month or so ago now there is a massive blog post queue), working for <a href="http://rulemotion.com/">Rulemotion</a> who use these technologies amongst others:</p>

<ul>
<li>OMeta</li>
<li>SBVR</li>
<li>JS</li>
<li>CoffeeScript</li>
<li>NodeJS</li>
<li>OData</li>
</ul>

<p>My job in Athens is two fold:</p>

<ul>
<li>Write some OMeta stuff somewhere (They have a specific project/task - don't worry)</li>
<li>Look at the overall project and give my honest feedback</li>
</ul>

<p>Well, giving honest feedback is something I can do - however my relationship with OMeta and SVRB is that I've never heard of them.</p>

<p><strong>It looks like I have some learning to do</strong></p>

<p>So what IS OMeta? It turns out that I do have a little experience in this area because OMeta is a expression parsing language, and like most people I've written a few parsers and compilers in my few years as a software developer.</p>

<p>OMeta is a bit different in that it had a specific goal - chiefly that of making it fast to prototype new languages/parsing constructs, and indeed it can be used to do pretty much the whole chain in the compilation process (parsing, intepreting and compilation).</p>

<p>You can read the <a href="http://www.vpri.org/pdf/tr2008003_experimenting.pdf">original paper</a>, it's the best source of information apart from just reading the implementation.</p>

<p><em>I'm not going to do a blog series on this, just wanted to throw up some stuff as I learned it :)</em></p>

<p><strong>What I'm using</strong></p>

<p>I have <a href="https://github.com/Page-/ometa-js">OMeta-JS</a>, and I'm doing most of my playing in the web browser with <a href="https://github.com/Page-/ometa-js/tree/highlighting/examples/highlighting">An OMeta parsing Ometa demo</a>.</p>

<p>If I make some OMeta in the textbox and then go to the other textbox, I can copy and paste the JS into a repl and play around, it's not the most super effective way of working but I suspect this demo will be improved on to make it easier.</p>

<p><strong>So again, what is OMeta?</strong></p>

<p>I told you, it's a parsing language, check out the following:</p>

<pre><code>ometa MyParser {
  greeting = "Hello"
}
</code></pre>

<p>If I compile this, I'll get the following:</p>

<pre><code>var MyParser = OMeta._extend({
  greeting: function() {
      var $elf = this, _fromIdx = this.input.idx;
      return this._applyWithArgs("token", "Hello");
  }
});
</code></pre>

<p>Which I can use in some code</p>

<pre><code>MyParser.matchAll("Hello", "greeting")    : Success
MyParser.matchAll("Goodbye", "greeting")  : Failure
</code></pre>

<p>What I can also do is transform these expressions into other expressions</p>

<pre><code>ometa MyParser {
  greeting = "Hello" -&gt; "Howdy"
}

MyParser.matchAll("Hello", "greeting")    : "Howdy"
</code></pre>

<p>And I can also build up matches out of other matches</p>

<pre><code>ometa MyParser {
  greeting = "Hello",
  bob      = "Bob",
  sentence = greeting bob
}

MyParser.matchAll("Hello Bob", "sentence")  : Success
MyParser.matchAll("Hello James", "sentence")  : Failure
MyParser.matchAll("Bob", "bob")  : Success
</code></pre>

<p>And this means I can build up transformations from simple expressions:</p>

<pre><code>ometa MyParser {
  greeting = "Hello" -&gt; "Howdy ",
  bob      = "Bob"   -&gt; "Bobby"
  sentence = greeting:g bob:b -&gt; (g + b)
}

MyParser.matchAll("Hello Bob", "sentence")  : "Howdy Bobby"
MyParser.matchAll("Hello James", "sentence")  : Failure
</code></pre>

<p>Now obviously we don't use this language for parsing daft sentences like the above, what we do is use it to build up expectations around structures such as program code.</p>

<pre><code>ometa CParser {
  type    = identifier,
  argList = listOf(arg, ","),
  methodBody = "{" statementList "}"
  program = type "main("  argList ")" methodBody
}
</code></pre>

<p>And so on...</p>

<p>Now this is getting ahead of myself, let me write about how I got to grips with OMeta by writing a JSON parser...</p>]]></description><link>http://codeofrob.com/entries/learning-ometa-in-greece.html</link><guid isPermaLink="true">http://codeofrob.com/entries/learning-ometa-in-greece.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Tue, 02 Apr 2013 09:30:00 GMT</pubDate></item><item><title><![CDATA[I am interested in talking about work]]></title><description><![CDATA[<p>By the time July rolls around, I will have spent half a year travelling around <a href="/entries/i-am-not-looking-for-a-job.html">working for free</a>, learning new technologies, picking up new skills and in general becoming a <a href="/entries/a-note-on-working-hours-and-working-at-home.html">happier person</a>.</p>

<p>I can't keep doing this forever, aside from the slow drip of money out of my bank accounts I already miss having a permanent base to go back to.</p>

<p>So, from July I'll need to start earning a regular or semi-regular income once more, and it is therefore time to publicise let the world know I'm ready for it again.</p>

<p><strong>Who am I?</strong></p>

<p>I have spent the past decade delivering software primarily in the Microsoft space with a focus on C# and JS. I mostly end up in charge of the software projects I'm involved with and have a focus on keeping the team's options open and able to react to change.</p>

<p>I am a regular on the conference circuit and tend to talk about testing, javascripts and pragmatic development in .NET.</p>

<p>I write code, I write a <em>lot</em> of code, I have the ability to learn things <em>quickly</em> and start delivering early on after starting a new role and I am an enthusiastic sharer of ideas and opinions.</p>

<p><strong>What I'm offering</strong></p>

<p>I am offering my nimble fingers and active mind to anyone in the world, I can...</p>

<ul>
<li>Help build features, and teach at the same time</li>
<li>Run workshops on JS (back-end or front-end), ASP.NET MVC and RavenDB</li>
<li>Improve your testing strategies</li>
<li>Help remove obstacles from your development process!</li>
<li>Help you move forward from your legacy issues (Silverlight to ...?)</li>
<li>Advise on your long-term architectural problems/goals</li>
</ul>

<p>I am good at shipping code, I am knowledgable in many areas of .NET development and have spent a lot of time using and developing against alternative databases for the past few years.</p>

<p><strong>What I looking for</strong></p>

<p>I am flexible, I ask for you to be the same. I am always happy to travel on-site providing my expenses are covered, but I think I am going to start renting a house again and will probably want to be spending some time there in between trips.</p>

<p>I am most likely looking for short-term consultancy work (4-5 days) and short-term development work (2-8 weeks). </p>

<p>I am looking for work in any country; as mentioned above I'm happy to travel.</p>

<p>My rates are flexible and tend to vary depending on country, convenience and company. I am looking to sustain a lifestyle and can therefore offer flexibility.</p>

<p><strong>So</strong></p>

<p>Do get in touch at <a href="mailto:robashton@codeofrob.com">robashton@codeofrob.com</a> and ask me for availability from July onwards, I am already starting to fill my calendar with paid work from that date onwards so will likely need advance notice for anything more than a week or so.</p>]]></description><link>http://codeofrob.com/entries/i-am-interested-in-talking-about-work.html</link><guid isPermaLink="true">http://codeofrob.com/entries/i-am-interested-in-talking-about-work.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Mon, 01 Apr 2013 09:30:00 GMT</pubDate></item><item><title><![CDATA[My relationship with SOLID - The overloaded D]]></title><description><![CDATA[<p>My week of SOLID: so far:</p>

<ul>
<li><a href="/entries/my-relationship-with-solid---starting-with-s.html">S</a>ingle responsibility</li>
<li><a href="/entries/my-relationship-with-solid---the-big-o.html">O</a>pen closed</li>
<li><a href="/entries/my-relationship-with-solid---the-misunderstood-l.html">L</a>iskov substitution</li>
<li><a href="/entries/my-relationship-with-solid---seeing-i-to-i.html">I</a>nterface segregation</li>
<li><a href="#">D</a>ependency inversion</li>
</ul>

<p>We've reached D, and that's where the wave we started with L finally hits the shore and materialises into something we can use.</p>

<p><blockquote>
A. High-level modules should not depend on low-level modules. Both should depend on abstractions.
  </blockquote></p>

<p><blockquote>
B. Abstractions should not depend upon details. Details should depend upon abstractions.
  </blockquote></p>

<p>We've been using that Stream example for the last couple of blog entries and we'll pull that out one last time as an example:</p>

<p>Stream is an example of a <em>low level module</em>, and we can consider IStream to be an abstraction of that, which <em>high level modules</em> can consume</p>

<pre><code>public interface IStream {
  void Read();
  void Write();
  void Seek();
}

public class Stream : IStream { etc }
</code></pre>

<p>However, this is still not really an abstraction, the abstraction is a lie because it is an exact mirroring of the actual Stream object. (this is okay sometimes as we'll see below)</p>

<p><strong>How I like to code sometimes</strong></p>

<p>I'm writing a high level module, let's say it's a Controller, and it needs to construct a view model for return to the outside world for rendering in a View of some sort. </p>

<p>Let's mix it up a little bit and do it in NodeJS like I'm pretty much doing everywhere at the moment.</p>

<pre><code>app.get('/ponies', function(req, res) {

})
</code></pre>

<p>I don't like to typically make decisions in a long-term project about persistence until I know more about my use cases, and indeed in this case I don't even want to care that persistence is even happening - instead, what I'll usually do is say to the outside world, <em>I need something that houses ponies</em></p>

<pre><code>module.exports = function(app, stable) {
    app.get('/ponies', function(req, res) {
      var ponies = stable.availablePonies(req.params.count, req.params.pagesize, req.params.page)
      res.send(ponies)
    })
}
</code></pre>

<p>What is stable? Well, stable was instantiated by the Application Root and I don't care what stable is, a basic implementation (and indeed the one I start off with is)</p>

<pre><code>stable = new InMemoryStable()
</code></pre>

<p>This allows me to write features quickly, allows me to write functional tests that are relatively fast and allows me to iterate on these things quickly and defer the decision about persistence until it becomes necessary to deal with it (if it does at all)</p>

<p>The important point here is that implicit interface being defined here (I'm in JS, we haven't got a real interface), let's call it "IHousePonies" has been dictated by the high level module and it doesn't care what the low level code behind that interface does.</p>

<p>That's an inversion of responsibility and it's a good one too because it means I'm unlikely to run into violations of <a href="/entries/my-relationship-with-solid---seeing-i-to-i.html">ISP</a> because the high level module <em>requires</em> that the functionality on that interface be present on all implementations of that interface.</p>

<p>This is close-ish to what some people would describe as using <a href="http://martinfowler.com/bliki/RoleInterface.html">role interfaces</a> which are worth reading up on. Certainly when I'm putting my software-engineering hat on and I'm working on a project where things are likely to be complex, there are likely to be quite a few moving parts and code quality is important I'll lean in this direction.</p>

<p><strong>How I like to code other times</strong></p>

<p>If I'm in .NET helping build the standard ASP.NET MVC application that clients tend to want, I'll pull out RavenDB which has an in-memory mode and use its interfaces directly across my application. They are an abstraction already and that abstraction hides</p>

<ul>
<li>The use of RavenDB as an embedded database</li>
<li>The use of RavenDB as a remote HTTP database</li>
<li>The use of RavenDB as an in-memory database (for testing)</li>
</ul>

<p>Sticking our own abstraction around this makes very little sense, although if we have complicated domain logic we might end up with some coordinators between the controller and RavenDB.</p>

<p>In most cases the effort of building up abstractions over time from our high level controllers won't really have much of a pay off.</p>

<p>Of course, if elsewhere in that project I have the need to do something that isn't CRUD, then the use of my own abstractions will come into things because hiding the low level details from the high level consumers is still important. These abstractions can be built up over time as needed, rather than defining them all up front.</p>

<p><em>Insert any other similar technologies into the above scenarios and it's pretty much the same</em></p>

<p><strong>How any of this can relate to testing</strong></p>

<p>Well, if we're describing our dependencies on other modules as interfaces that we own, we can create in memory representations of those dependencies in the form of mocks, stubs or full-blown in-memory implementations (the latter being my personal preference in most cases)</p>

<p>Having ownership of the interfaces that we rely on means we can dictate the desired behaviour via tests (or in some languages code contracts), and it means that the tests we write for our module can make assumptions about how the code behind that abstraction is going to work.</p>

<p>Coupling this design principal with techniques such as <a href="http://en.wikipedia.org/wiki/Dependency_injection">Dependency Injection</a> means that we can make it very clear to the outside world from our module what abstractions we rely on, and allow the outside world to make decisions about what it is we are going to actually get.</p>

<p><strong>How it can all go wrong - attack of the killer interfaces</strong></p>

<p>What happens in a lot of projects is that we decide that the reason for DI is for testing, and isolation is really important so we need to have abstractions for everything, and almost everywhere we end up with</p>

<pre><code>public class Something
public interface ISomething
</code></pre>

<p>Because every class needs an interface in order to be mockable - we forget to apply the inversion part of dependency inversion and instead we just focus on dependencies for our tests.</p>

<p>This isn't helped by most popular IOC frameworks and their default convention that it'll automatically bind instances like the above for us.</p>

<p>This is awful, when we think about inverting the relationship between our high level modules and low level modules, we should be thinking about it in terms of pay-off and not dancing around for the sake of writing pointless low level tests for code with little real behaviour.</p>

<p>We should be limiting our abstractions to the tune of rather than thinking about everything at the class level, thinking about things at the module level (which could be a collection of classes that talk to each other and require some external data/input)</p>

<p><strong>SOLID - where did it all go wrong?</strong></p>

<p>I could go on about this till the cows come home, but I don't want to because I've got some stuff to build, so I'll leave it here with a final note:</p>

<p><strong>ALL</strong> of the SOLID principles are <em>great</em>, as a guideline for thinking about code as we write it, I'm not disagreeing with that at all. What I disagree with are statements that say "MUST" or "NOT ALLOWED" etc - because most developers are not master craftsmen (or whatever you call yourselves these days) and trying to make them write code as if they are is what leads to disaster.</p>

<p>Most code should be allowed to grow organically, and caution should be exercised in making sure that we don't end up with that big ball of mud that everybody fears - absolutely. Trying to avoid that big ball of mud by blindly following the SOLID principles leads to the creation of a big haystack where the actual functionality is a needle hidden somewhere underneath.</p>

<p><strong>fin</strong></p>]]></description><link>http://codeofrob.com/entries/my-relationship-with-solid---the-overloaded-d.html</link><guid isPermaLink="true">http://codeofrob.com/entries/my-relationship-with-solid---the-overloaded-d.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Fri, 29 Mar 2013 09:30:00 GMT</pubDate></item><item><title><![CDATA[My relationship with SOLID - Seeing I to I]]></title><description><![CDATA[<p>The <a href="http://en.wikipedia.org/wiki/Interface_segregation_principle">interface segregation principle</a> is slightly more relevant to the code that I write day to day than <a href="/entries/my-relationship-with-solid---the-misunderstood-l.html">Liskov</a>.</p>

<p><blockquote>
  The interface-segregation principle (ISP) states that no client should be forced to depend on methods it does not use. 
  </blockquote></p>

<p>I talked <a href="/entries/my-relationship-with-solid---the-misunderstood-l.html">yesterday</a> about the Stream class, and showed how</p>

<pre><code>public class Stream {
  public virtual bool CanRead { get; }
  public virtual bool CanWrite { get; }
  public virtual bool CanSeek { get; }

  public virtual void Read(Byte[] buffer, int offset, int amount) {}
  public virtual void Write(Byte[] buffer) {}
  public virtual void Seek(int offset){}
}
</code></pre>

<p>Wasn't necessarily a violation of Liskov because the variations in its behaviour were well described by those slightly uncomfortable properties.</p>

<p>However, those awkward properties definitely point towards a violation of the ISP. Why? Because we have an interface - (in this case, an implicit one dictated by the Stream base class) which looks like this:</p>

<pre><code>interface Stream {
  void Read(Byte[] buffer, int offset, int amount);
  void Write(Byte[] buffer);
  void Seek(int offset);
}
</code></pre>

<p>And yet not all Streams can do all of those things, hence we resort to those rather opaque properties.</p>

<p>Perhaps another way we'll often see violations of this in code (let's say we didn't have those properties) is the checking for specific types in methods that use the interface such as:</p>

<pre><code>if(stream is FileStream)
  stream.Write(bytes, 0, bytes.Length)
</code></pre>

<p><em>shudder</em>, this stuff be bad as not only do we open up ourselves for runtime crashes when a consumer passes in something we don't recognise but we're writing opaque behaviour into our code that'll confuse consumers of that code.</p>

<p><strong>Interface segregation to the rescue</strong></p>

<pre><code>public interface IRead {
  void Read(Byte[] buffer, int offset, int amount);
}

public interface IWrite {
  void Write(Byte[] buffer);
}

public interface ISeek {
  void Seek(int offset);
}
</code></pre>

<p>When we have methods that require something that Reads, we can pass in IRead, when we have methods that require something that Writes can pass in IWrite, and this is great, what if we need something that Reads <em>and</em> Writes</p>

<pre><code>public interface IReadAndWrite : IRead, IWrite {}
</code></pre>

<p>Okay, maybe we can do this, but what about something that Reads Writes and Seeks?</p>

<pre><code>public interface IReadAndWriteAndSeek : IRead, IWrite, ISeek {}
</code></pre>

<p>Now this is a bit contrived, but this is one of the reasons the .NET team made the decision to go with the CanRead/CanWrite approach beacuse otherwise we'd either simply revert to checks like</p>

<pre><code>if(Stream is IRead)
</code></pre>

<p>or have to do stuff with generics like</p>

<pre><code>void WriteToFile&lt;T&gt;(T stream, string filename) where T : IRead, IWrite, ISeek
</code></pre>

<p><em>shudder</em></p>

<p><strong>Framework Engineering</strong></p>

<p>If you're writing a framework, first off stop and don't do that... but okay, if you're writing a framework these are the compromises that you'll sometimes have to make - and that's okay.</p>

<p>Well described behaviour that's a little bit awkward is better than having a pile of interfaces that we have to dance around if we want to achieve something meaningful.</p>

<p>As mentioned yesterday, I actually don't mind the .NET teams decision to break ISP here because the usage of these streams would be much harder with the number of variations in behaviour a stream can actually have.</p>

<p>Tomorrow we'll look at why ISP is irrelevant in the grand scheme of things however, as we reach the final entry in this little brain-dump and talk about DI and how it encourages the use of role interfaces.</p>]]></description><link>http://codeofrob.com/entries/my-relationship-with-solid---seeing-i-to-i.html</link><guid isPermaLink="true">http://codeofrob.com/entries/my-relationship-with-solid---seeing-i-to-i.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Thu, 28 Mar 2013 09:30:00 GMT</pubDate></item><item><title><![CDATA[My relationship with SOLID - The misunderstood L]]></title><description><![CDATA[<p>I imagine my statement yesterday that OCP is "dead" will be the big bomb out of all of these blog entries, but nevertheless we push forward and look at the <a href="http://en.wikipedia.org/wiki/Liskov_substitution_principle">Liskov substitution principle</a></p>

<p><blockquote>
   If S is a subtype of T, then objects of type T may be replaced with objects of type S (i.e., objects of type S may be substituted for objects of type T) without altering any of the desirable properties of that program (correctness, task performed, etc.)
  </blockquote></p>

<p>This is one of those cases where things <em>just make sense</em>, and yet people always have a hard time describing exactly what it is. I'm probably not going to spend much time on it in this blog entry because it's really boring and I doubt I can do a better job of explaining it than anybody else.</p>

<p><em>Instead, my relationship with it..</em></p>

<p>Well, I'll start off by saying that day to day that Liskov means nothing to me, it's almost a rule that strictly applies itself to inheritance situations and because I'm primarily these days working in langauges that don't have any real native inheritance mechamisms (prototype chaining doesn't really count), this isn't something that affects me.</p>

<p>Hell, you know what? When I'm working in C# it is something that I don't run into because inheritance is generally something I don't use or take advantage of (because composition is usually simpler etc etc). You can't change the behaviour of an object through inheritance if you never use it.. right? :-)</p>

<p>Nevertheless, I want an example anyway, and I want one we're all familiar with so I'll hit up the .NET framework, and while I can remember vague instances of being annoyed about violations in UI frameworks like WinForms those days a long behind me and I can't remember any of them.</p>

<p>Indeed it's actually hard to think of any examples of this in the .NET framework which aren't actually a violation of our next guideline ("interface segregation"),  and throughout the "SOLID years" if you look at other people's writing on this subject, most writings about Liskov are actually about Interface Segregation.</p>

<p>So let's hit up a commonly quoted example that is almost a violation and talk about it a little bit.</p>

<p><em>The oft-quoted Stream example</em></p>

<p>Looking at the design principles that produced it, the reasoning is quite clear about why the .NET team went in the direction they did with this one, let's expand and use a simplified version of the Stream class.</p>

<pre><code>public class Stream {
  public virtual void Read(Byte[] buffer, int offset, int amount) {}
  public virtual void Write(Byte[] buffer) {}
  public virtual void Seek(int offset){}
}
</code></pre>

<p>Now, the default behaviour of this is to throw an exception on any of those methods, and derived instances can do proper implementations of these, like so</p>

<pre><code>public class FileStream : Stream {
  public override void Read(Byte[] buffer, int offset, int amount) { // Read from the file }
  public override void Write(Byte[] buffer) { // Write to the file }
  public override void Seek(int offset){ // Seek to a position within the file }
}
</code></pre>

<p>And maybe an implementation that reads from a HTTP request</p>

<pre><code>public class HttpStream : Stream {
  public override void Read(Byte[] buffer, int offset, int amount) { // Read from the file }
  public override void Write(Byte[] buffer) { throw new NotSupportedException(); }
  public override void Seek(int offset){  throw new NotSupportedException(); }
}
</code></pre>

<p>Now, at this point if we were to pass around the Stream object to a method like this</p>

<pre><code>public void ReadStreamIntoFile(string filename, Stream stream);
</code></pre>

<p>Then our two streams would work just fine. </p>

<p>However, if we were to pass the stream object into this method:</p>

<pre><code>public void WriteFileIntoStream(string filename, Stream stream);
</code></pre>

<p>The FileStream would function correctly, and the HttpStream would throw a NotSupportedException.</p>

<p>This is why the Stream class is often quoted as an example, the derived instances change the behaviour in program-breaking ways.</p>

<p><em>However</em></p>

<pre><code>public class Stream {
  public virtual bool CanRead { get; }
  public virtual bool CanWrite { get; }
  public virtual bool CanSeek { get; }

  public virtual void Read(Byte[] buffer, int offset, int amount) {}
  public virtual void Write(Byte[] buffer) {}
  public virtual void Seek(int offset){}
}
</code></pre>

<p>The behaviour as described, is that if those properties return true, then the methods are safe to call, if they return false, they're not safe to call.</p>

<p>It's opaque, and feels a bit wrong - but we don't necessarily have a violation of Liskov and we're happy on this front. This is a good example of where the pragmatics of developer usage have overidden the following of arbitrary software-design "rules".</p>

<p><strong>Back to my relationship with Liskov</strong></p>

<p>I do not have a relationship with the Liskov substitution principle because I don't generally write code that has any sort of inheritance chain within it, but if I did - sometimes I guess I'd end up in the situation like the above and that would be okay. I'm okay with that for the most part.</p>

<p><strong>Summary</strong></p>

<p>Liskov is ultimately pretty boring, and unless you're writing code with lots of inheritance it isn't really a problem. Don't write code with lots of inheritance and keep this problem away from you. Winning.</p>

<p>As a design principle, I totally agree with it - changing derived classes behaviour is annoying, don't do it. Okay, sorted.</p>]]></description><link>http://codeofrob.com/entries/my-relationship-with-solid---the-misunderstood-l.html</link><guid isPermaLink="true">http://codeofrob.com/entries/my-relationship-with-solid---the-misunderstood-l.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Wed, 27 Mar 2013 09:30:00 GMT</pubDate></item><item><title><![CDATA[My relationship with SOLID - The big O]]></title><description><![CDATA[<p><strong>Open closed is dead, long live Open closed</strong></p>

<p>I'm blogging about <a href="/entries/my-relationship-with-solid---starting-with-s.html">SOLID</a> for some reason, and now we're onto the beast that set me off:</p>

<p><strong>OCP</strong></p>

<p>Yikes</p>

<p><blockquote>
    They are “Open For Extension”. This means that the behavior of the module can be extended. That we can make the module behave in new and different ways as the requirements of the application change, or to meet the needs of new applications.
  </blockquote></p>

<p>and</p>

<p><blockquote>
    They are “Closed for Modiﬁcation”. The source code of such a module is inviolate. No one is allowed to make source code changes to it.
  </blockquote></p>

<p>Thanks <a href="https://docs.google.com/file/d/0BwhCYaYDn8EgN2M5MTkwM2EtNWFkZC00ZTI3LWFjZTUtNTFhZGZiYmUzODc1/edit?hl=en">Uncle Bob</a>, you're right, this <em>is</em> <a href="http://blog.8thlight.com/uncle-bob/2013/03/08/AnOpenAndClosedCase.html">over-stated</a>, and because it's so over stated, I believe it to be the cause of so many of the over-designed pieces of crap I've had to deal with in my career :-)</p>

<p>This is the conversation I imagine developers having with themselves when writing this stuff, I don't have to imagine too hard because I've been there too:</p>

<p><blockquote>
    What if somebody at some point wants to change this so they can have another behaviour for this value, I'd better use the strategy pattern here instead of this switch statement, but oh my word now I've done that what if somebody wants to use this code from some other system than this one, I'd better stick a command system in front of this and use double dispatch for handling them - but wait, what if other code needs to react from this and do something else, I'd better raise a pile of events, but what if those aren't enough I'd better make sure I split all this behaviours out into their own interfaces so they can be overridden and...
  </blockquote></p>

<p>And on it goes until suddenly what was a couple of classes behind a controller or presenter blow up into a mess of a hundred classes that all do the square root of diddly squat, but together manage to cause a lot of headaches for anybody coming across the code in the future.</p>

<p>Now, I'm sure this wasn't the intent behind these statements, and it sure isn't now - but you know what?</p>

<ul>
<li>I don't really care what the original sentiment was behind Uncle Bob's statement.</li>
<li>I don't really care what it is actually supposed to mean. </li>
<li>I <em>do</em> care that code that I come into contact with doesn't get in my way when I want to add a feature</li>
</ul>

<p>Here is my current thinking on the Big O. Let's make it stand for "Open", and remove the CP.</p>

<p><blockquote>
    Good code is code that another developer can change the behaviour of easily and clearly see the consequences of that change.
  </blockquote></p>

<p>The decisions made when designing a language can have implications on how we satiate this need.</p>

<p>We can look to <a href="http://twitter.com/jonskeet">@jonskeet</a>'s perfect language where "all classes are sealed by default, all methods are sealed by default, all extensibility points are explicitly defined", or we can look at any of the no-holds barred dynamic languages that let us get away with pretty much anything.</p>

<p><strong>Let's take option one</strong></p>

<p>Let's say we <em>do</em> make that call (because Jon is where all of this started, so taking his perspective will help see where he is coming from), then surely if we're going to follow OCP then we have to from the very beginning bake in these extension points on a <em>just in case</em> basis. </p>

<p>Woah! No!!! Stop right there. This is how we end up with the kind of code where we use the strategy pattern everywhere and have a million and one interfaces to describe the act of doing absolutely nothing of consequence at all.</p>

<p><em>The best code is code that can be changed easily</em>, code that is easy to read, code that keeps state close to the behaviour, code that that doesn't attempt magic tricks, code that anybody can read - this is the code meets this standard. </p>

<p><strong>Let's take option two</strong></p>

<p>Now we're in the magical happy land of dynamic languages, and we can just screw over any object by fiddling with its prototype, the rules have gone out of the window. This is the <em>land of possibility</em> people, and we have the <em>power to change things</em>.</p>

<p>Does this mean we haven't got to worry about OCP? Nay - this is not so. Having the ability to change anything is <em>fantastic</em>, people <em>don't</em> know everything when putting together a module, and having everything open by default means that while you wait for the project you're using to have an appropriate extension point you can hack around it and get on building your product.</p>

<p>However, explicitly defined extension points have clearly defined behaviours and are predictable - so are clearly desireable.</p>

<p><strong>Wait a second</strong></p>

<p>Getting off the subject of how languages can affect our decisions, we can look at how our programming culture can have an impact on it. </p>

<p>I find it intensely irritating that the languages that lean towards the "closed by default" design also seem to live in the environment where the code itself is also "closed by default", which means that either the framework authors have to build in extension points for everything imaginable or the users of that framework code have to suffer for it.</p>

<p>I find it intensely amusing that the languages that lean towards the "open by default" design also live in the environment where the code itself is open by default (this is the age of Github), which means that the people with the problem can come in, make the desired change and move on with their projects with barely any thought to it at all.</p>

<p>And this is where I go back on what I said in all the statements above, <em>this</em> is where OCP is now, times have changed since the original sentiment was uttered, we have a lot more open source now and the ideal is:</p>

<ul>
<li>Building small disposable modules that live in package systems and on Github/etc</li>
<li>Primarily building products out of these open source building blocks</li>
<li>These building blocks are either replacable in a few hours work, or easily extended via a pull request</li>
<li>These building blocks can be forked for your project and changes merged from upstream with little effort</li>
</ul>

<p>This changes the very face of things, this changes how we build software - and it means that a strict adherence to OCP becomes largely a thing restricted to stodgy enterprise environments that are slow moving, uncompetitive and slow to get things done (and they're welcome to it)</p>

<p>The true future of OCP is in building these open source little packages that are easily changed or forked, and in that we can find an elegance and simplicity that I find quite pleasing.</p>

<p>If we're forking a module and sticking a new version on it, we're saying that it is no longer the same as the old module, it is new code and the old code still exists too.</p>

<p><strong>Where OCP makes sense</strong></p>

<ul>
<li><p>An example of where this sort of thinking has relevance, is in technical patterns like event sourcing, where once an event becomes committed, it becomes preferable to create new versions of that event rather than modify the original (because events can't be changed, they already happened - etc)</p></li>
<li><p>An example of where this sort of thinking has relevance, is where you have code that starts being modified in the same way repeatedly (such as adding further conditions to an if statement), and this modification has cost and side-effects. Refactoring towards simplicity usually has the effect of removing this sort of repetitive action and indeed that code will become closed to modification over time as it matures.</p></li>
<li><p>Repetition actually has the key, if you're constantly touching  the same piece of code again and again over time, then that piece of code is probably, as <a href="http://twitter.com/gregyoung">@gregyoung</a> puts it, a "bug hive". If you have this sort of pattern in your source control then that code is likely brittle because it hasn't been refactored over time towards making it easier to extend without breaking stuff.</p></li>
<li><p>Coupled with a practical application of the single responsibility principle, we can say that if we're changing a piece of code too much either our requirements are just changing a lot (at which point you're not changing code you're throwing old code away and replacing it), or our code is trying to do too much.</p></li>
</ul>

<p><strong>Summary</strong></p>

<p>So, in the age of tiny disposable modules that do just one thing, OCP is dead (<em>wink</em>) - who'd have thunk it. <em>/dramatic oversimplification</em></p>]]></description><link>http://codeofrob.com/entries/my-relationship-with-solid---the-big-o.html</link><guid isPermaLink="true">http://codeofrob.com/entries/my-relationship-with-solid---the-big-o.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Tue, 26 Mar 2013 10:00:00 GMT</pubDate></item><item><title><![CDATA[My relationship with SOLID - Starting with S]]></title><description><![CDATA[<p>I saw a tweet by <a href="http://twitter.com/jonskeet">@jonskeet</a> the other day which caught my eye:</p>

<p><blockquote class="twitter-tweet"><p>(I know that doubting things like OCP is pretty close to heresy, but it's just <em>never</em> made sense to me.)</p>&mdash; Jon Skeet (@jonskeet) <a href="https://twitter.com/jonskeet/status/309911260701552640">March 8, 2013</a></blockquote>
  <script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></p>

<p><em>Well okay then</em></p>

<p>Well, obviously I kinda agree with this sentiment if you go and hit up the <a href="http://blog.8thlight.com/uncle-bob/2013/03/08/AnOpenAndClosedCase.html">"Immature" 43 year old Uncle Bob's</a> statement which is as written:</p>

<p><blockquote>
    They are “Closed for Modiﬁcation”. The source code of such a module is inviolate. No one is allowed to make source code changes to it.
  </blockquote></p>

<p>But this got me thinking more widely on my relationship with SOLID as a whole and how that has changed over the years. It reminded me how many times (like the GoF patterns) I've seen an over-zealous and misunderstanding of these concepts <a href="/entries/the-fallacy-of-the-dreyfus-model-in-software-development.html">wreak havoc in codebases</a>.</p>

<p>I've been able to quote the "rules" from SOLID word for word this past half-decade quite easily, but my relationship and understanding of how these seemingly innocuous statements impact my code has changed over time much like <a href="/entries/uncle-bobs-viewpoint-considered-harmful.html">my relationship and understanding of TDD</a></p>

<p>So, for the next 5 entries, I will jot down my current relationship with SOLID without too much thought or proof-reading (<em>Okay, I lied, I got a few people to read these because I wanted to avoid pedantry</em> - thanks folk)</p>

<p><strong><a href="http://en.wikipedia.org/wiki/Single_responsibility_principle">The single responsibility principle</a></strong></p>

<p><blockquote>
    In object-oriented programming, the single responsibility principle states that every class should have a single responsibility, and that responsibility should be entirely encapsulated by the class. 
  </blockquote></p>

<p>This is the kind of statement that leads to <a href="http://ayende.com/blog/154177/limit-your-abstractions-so-what-is-the-whole-big-deal-about">this sort of mess</a>, </p>

<p><blockquote>
    "but omg my controller should only be routing and my service should only be servicing and my data layer should only be data-ing."
  </blockquote></p>

<p>And this is unfair, and yet the confusion continues because people see several parts to the whole idea that</p>

<p><blockquote>
    a class should only have one reason to change <br/>
    a  class should only have one responsibility
  </blockquote></p>

<p>The problem is that most of the time the abstractions people come up with to limit a classes responsibility are <em>horizontal</em> in nature. The true power of single responsibility however, lies in the vertical.</p>

<p>Perhaps this is because they're easier to conceptualise, and easy to write frameworks and patterns for so we can feel productive in our day job - but this is really not as it should be.</p>

<p>What do I mean by horizontal? "I'm going to have a layer of controllers, a layer of validation, a layer of services, a layer of business logic,and a layer of data access". "If I put it behind an interface then I'll be alright".</p>

<p>What do I mean by vertical? "I'm going to write a feature to to manage the availability of books in this library"</p>

<p>Frameworks like ASP.NET MVC don't help us with this and their by-default grouping of horizontal concerns across a project, it makes it too easy to carry on grouping the horizontal concerns across a large project and pretend we have a nice clean architecture because we have folders to put things on.</p>

<p><em>Your relationship with state</em></p>

<p>A lot of the time it boils down to state, OO and state have a bit of a confusing relationship, and most of our efforts should be devoted to minimising the amount of mutable state that is exposed to concerns that aren't directly related to each other.</p>

<p>Funnily enough, despite the confusion this is actually pretty easy to conceptualise via tooling and metrics, if your classes are cohesive, most of the methods on that class will touch most of the state in that object. </p>

<ul>
<li>If half of the methods touch half of the state, and the other half of the methods touch the other half of the state then there are clearly two classes.</li>
<li>If you're constantly having to pass visitors around the place to get at private state, or expose state through getters, then you should probably be looking at merging code because you've spread responsibility too thin</li>
<li>If you're constantly passing state around in bags to be mutated by several other things, then you likely have the responsibilties spread out over several layers and you should likely be deleting those layers and putting the code in an object that looks to protect access to that state.</li>
<li>If you haven't got a lot of directly mutable state, then something somewhere probably is being mutated (such as in the database) and following that chain to the source will yield in answers similar to the above.</li>
<li>If you have to jump through more than a couple of classes to find the state that your behaviour is trying to modify, you've gone too far - keeping your mutable state close to the actual behaviour being enacted on it is the road to success</li>
</ul>

<p>Having a horizontal layer whose responsibility is "modifying state in the database" is nonsensical and vague.</p>

<p>Having several objects whose responsibility is looking after the state for a particular feature and then persisting it (perhaps via another facillitiating object) has a lot more sense in terms of understandability and traceability.</p>

<p><em>A note note on orthoganal concerns</em></p>

<p>State based data persistence is not (usually) an orthogonal concern, neither is the workflow/routing sat in front of your MVC application - logging on the other hand can be, and authentication/authorisation can be too. </p>

<p>Clearly, you shouldn't be constantly modifying these vertical slices because of a change to your authentication scheme or logging system. Trying to classify too many things as being orthogonal to your core functionality however is what leads to layer soup, and care should always be taken not to do this.</p>

<p>You can discover these as you go, there is nothing wrong with littering your code with these concerns to begin with, and then as things get repetitive, pulling them out to make life easier. Premature attempts at trying to isolate these concerns is often the path to layer soup.</p>

<p><em>Upwards from the class level</em></p>

<p>Trying to make classes whose concerns are limited, whose reason to change are limited is all very well and good, but it's no good looking at things under a microscope and saying <em>Hey, things look okay</em>, when you sit back and have to go <em>what is this crap?</em> </p>

<p>Let me invoke the <a href="http://codeofrob.com/entries/lots-of-small-things.html">NodeConf drinking game</a>, a lot of the time it is much more valuable to think of your codebase as a collection of modules which are independently versioned and have clear boundaries set up between them.</p>

<p>Any of these small modules can start off by being a complete and utter mess, and if further work is required in that area you can either re-write the module in a few hours, or refactor it as you go (did you say <em>spike and stabilise</em> again Rob? I think I did)</p>

<p><em>That</em> is where single responsibility really means something, and you can save a lot of time in development by building these disposable building blocks when you're rapidly iterating on a product.</p>

<p><em>Summary</em></p>

<p>I seem to have started with the least controversial and one of the most harmful of rules, oh well...</p>

<p>Thus ends my brain dump on responsibility and the many routes to layer soup. Tomorrow I'll go the heart of the matter on OCP, and then wind down the rest of the week through the rest of the set.</p>]]></description><link>http://codeofrob.com/entries/my-relationship-with-solid---starting-with-s.html</link><guid isPermaLink="true">http://codeofrob.com/entries/my-relationship-with-solid---starting-with-s.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Mon, 25 Mar 2013 09:30:00 GMT</pubDate></item><item><title><![CDATA[A note on working hours and working at home]]></title><description><![CDATA[<p>Yes yes yes, that whole <a href="http://www.huffingtonpost.com/2013/02/23/yahoo-working-remote_n_2750698.html">Yahoo thing</a>, whatever - there is more context to that story than "Banning working at home", although whether that is a solution to the problems is certainly up for debate.</p>

<p>I don't care about that, but it's what prompted Hadi to write <a href="http://hadihariri.com/2013/03/16/freedom-to-work/">this lovely article</a></p>

<p>I've been thinking about this a lot since <a href="/entries/i-am-not-looking-for-a-job.html">quitting my job</a> last December, as I've been travelling around and working for various people I've also found myself being given a lot of freedom as to how I apply my hours.</p>

<p>I've come to realise a certain "maturity" when it comes to my working hours, I passionately disagree with <a href="http://zachholman.com/posts/how-github-works-hours/">Zach Holman</a> where he describes being addicted to work and the line between work/life being heavily blurred as being a <em>good thing</em>(tm). That's total bullshit, and while you might have caught me doing that when I first started my career you will not find me doing it now.</p>

<p>Why not? Because there are <em>so many cool things to do</em> that aren't work - that's why.</p>

<p><strong>How I've found myself working when given freedom</strong></p>

<p>I've been rolling in at around 10am and then leaving once fatigue sets in and I feel that I'm no longer being <em>effective</em>. That can be any time between 4pm and 7pm on most days.</p>

<p>Yikes- that means on some days I've been working only 5 hours if you factor in lunch!!</p>

<p>However:</p>

<ul>
<li>Those five hours have been me dedicated to my task</li>
<li>Those five hours have been the most awake five hours of my working day</li>
<li>Coming in at 10am (ish) simply means I've woken up naturally rather than forced myself up at 7am</li>
<li>Leaving when I'm fatigued means I dont burn myself out so I can maintain a productive pace throughout this</li>
<li>I found myself doing a few hours on days off, presumable because I wasn't burned out from a week of pushing too hard</li>
</ul>

<p>It's hard to imagine that any of my clients these past four months would have any difficulty in <a href="http://ayende.com/blog/161185/robs-ravendb-sprint">describing</a> my output as "effective" or "productive"!</p>

<p><strong>Working together</strong></p>

<p>That said, core hours <em>are</em> useful, face time is useful, conversations are useful, communication is vital.</p>

<p>This is one of those matters in which good tooling <em>can</em> seriously help, enabling a combination of async communication such as Campfire, Flowdock, e-mail or IRC is vital in these circumstances. If your employees are working at home <em>and</em> they're not pulling their weight - then pulling them in isn't going to solve that problem. </p>

<p>Creating an environment in which your employees feel valued and free to apply their efforts how they see fit is not wasted effort, and I wish more companies would do that.</p>

<p>When I decide what I'm doing with regards to work (when summer hits), I find it hard to believe I'll be working at any company who is enforcing 9-5, or have some rigidly described "flexi-time" as part of their contract in an effort to seem cool. </p>

<p>I've had it with that sort of thing, this I know for sure. I love being an effective member of a team too much to put myself in a position where I feel obliged to sit in a seat for an no apparent reason ever again. (Future employers take note please)</p>]]></description><link>http://codeofrob.com/entries/a-note-on-working-hours-and-working-at-home.html</link><guid isPermaLink="true">http://codeofrob.com/entries/a-note-on-working-hours-and-working-at-home.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Fri, 22 Mar 2013 09:30:00 GMT</pubDate></item><item><title><![CDATA[Why I stopped using AMD]]></title><description><![CDATA[<p>I've been asked a few times why I've stopped using AMD as I move around and folk see my use of Browserify, here-in I try to write down my thoughts on why AMD doesn't make any sense to me any more.</p>

<hr />

<p>When I wrote a blog entry <a href="http://codebetter.com/robashton/2012/09/03/keeping-js-sane/">about 9 months ago</a>, I made the statement:</p>

<p><blockquote>
    The synchronous manner in which files are included in CommonJS-ish systems doesn’t lend itself to the web very well.
  </blockquote></p>

<p>I was wrong. I changed my mind, and as I've said before I am now a <a href="/entries/lots-of-small-things.html">Browserify Convert</a>.</p>

<p>What I didn't explain was what turned me off <a href="https://github.com/amdjs/amdjs-api/wiki/AMD">AMD</a> and in particular, <a href="http://requirejs.org/">RequireJS</a>.</p>

<p><strong>The list of things I want my module loader to help me with</strong></p>

<ul>
<li>I don't want to write all my code in a single file</li>
<li>I want to write my code across many files</li>
<li>I want to write my code across many modules</li>
<li>I want to be able to easily debug these once in the browser (it's unusual I need to debug, but when I do...)</li>
<li>I want the time between editing a file and seeing feedback in the application to be -- >&lt; -- this big</li>
</ul>

<p>In other words, yes - I do want the moon on a stick.</p>

<p><strong>RequireJS</strong></p>

<p>Seemed to help with these things, I didn't use the hideous ceremony-ridden version of AMD that looks like somebody vomitted in my Javascripts (that alone would have been enough to put me off) </p>

<p><em>The ceremonial way</em></p>

<pre><code>define([
  '../foo', 
  './lib/bar', 
  'boo'], 
  function(foo, bar, boo) {

})
</code></pre>

<p><em>The less-ceremony way</em></p>

<pre><code>define(function(require) {
  var foo = require('../foo')
    , bar = require('./lib/bar')
    , boo = require('boo')
})
</code></pre>

<p>So it was tolerable for a while because I didn't have to, however I would then run into the following road-blocks:</p>

<ul>
<li>What about Library X, does it support AMD?</li>
<li>If it doesn't support AMD, I have to add a shim? Should I patch the library?</li>
<li>What if it supports AMD, I'll want to load it from a libs directory</li>
<li>Where is the root of my application? What about sharing code client/server</li>
<li>What if I want to use CoffeeScript (or more recently for me, OMeta)</li>
</ul>

<p><strong>For every question, RequireJS had an answer</strong></p>

<p>And AMD's answer for <em>nearly every one of them</em> is to <em>add some configuration directives</em> or <em>write a r.js plug-in</em></p>

<p>And this is what put me off.</p>

<p>In no time at all, every project would have a configuration file many lines long of obscure directives (and I mean obscure directives, have you <a href="http://requirejs.org/docs/api.html">read the documentation?</a> - this is not intuitive and requires a hella lot of investment if we are to make effective use of it.</p>

<p>Then we'd want to write tests against the code, and we'd have to either attempt to re-use this configuration or duplicate it over into our tests directory. 
Then we'd run into problems with that configuration, and waste hours trying to work out a compromise to keep RequireJS happy.</p>

<p><strong>Most of those questions were the wrong question</strong></p>

<p>First off, using <a href="/entries/stop-using-relative-paths-in-your-javascripts.html">actual modules</a> has massive advantages over relative paths anyway, and while the build step of RequireJS will support these, this isn't going to work if we're using the A of AMD in development.</p>

<p>Secondly, if we want to compile our .coffee to JS, we should be using the coffeescript compiler to do this. If we want to compile our Typescript to JS likewise, if we want to import static files for templates then this should be part of our build process.</p>

<p>Trying to do everything as a long sequence of plug-ins meant to support the A/MD actually makes things a lot <em>slower</em> in my experience, because we're not trying to do it only when specific files change but instead trying to do it as part of the request pipeline (unless we go to lengths to work around the r.js plug-in system)</p>

<p><strong>The future of JS modules is not async anyway</strong></p>

<p>If yo look at the specifications and where they're going, (while last I checked they weren't perfect yet), the module system that is coming for JS isn't going to be asynchronous - and this is because our program <em>can't run until it's loaded anyway</em> - it actually makes little sense to add the overhead of asynchronous management to this process.</p>

<p>Building up an entire codebase around tooling that isn't compatible with how the future-web is going to work doesn't make an awful lot of sense, building up an entire tool-chain around this tooling makes even less sense.</p>

<p><strong>I switched to Browserify</strong></p>

<p>As I've said, I'm not particularly sold on using node_modules for  client-side code, but the module system in node <em>does</em> work, and <em>does</em> encourage us to package things up in a neat re-usable manner (I'm not sold on component.js yet either).</p>

<p>However, the code we write doesn't care what module system is being used if we're just doing CommonJS - it just knows that they come from <em>somewhere</em>. The tools we use to convert CS into JS don't care that we're using Browserify to package the end-result. The tools we use to embed templates in the downloadables don't care that we're using Browserify to do this. </p>

<p>In a nut-shell, Browserify is allowing me to hedge my bets by not coupling my workflow too closely to it. It doesn't come with pages of obsuse documentation and every time I pump out a new module into my little eco-system I am ever so thankful for this.</p>

<p>It has enabled me to be liberal with my module creation and not care how people are going to actually consume these packages (apart from 'through npm' somehow), and I've not had to debug or diagnose issues with it in the whole time I've been using it.</p>

<p>Let's look at the list of things I want:</p>

<ul>
<li>I don't want to write all my code in a single file</li>
<li>I want to write my code across many files</li>
<li>I want to write my code across many modules</li>
<li>I want to be able to easily debug these once in the browser (it's unusual I need to debug, but when I do...)</li>
<li>I want the time between editing a file and seeing feedback in the application to be -- >&lt; -- this big</li>
</ul>

<p>I'm able to do all of these - yes I need a build step now, but you know what? We need a build-step anyway if we're going to take advantage of the module system properly - even in RequireJS so this isn't a big deal. </p>

<p>We get debugging support through source maps (and this even tells us which module we're debugging) and as I said yesterday, I no longer really <a href="/entries/stop-using-relative-paths-in-your-javascripts.html">use relative paths</a> so I'm a great deal happier about my JS.</p>

<p>Happiness and productivity, good reasons for doing most things really.</p>]]></description><link>http://codeofrob.com/entries/why-i-stopped-using-amd.html</link><guid isPermaLink="true">http://codeofrob.com/entries/why-i-stopped-using-amd.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Thu, 21 Mar 2013 09:30:00 GMT</pubDate></item><item><title><![CDATA[Stop using relative paths in your JavaScripts]]></title><description><![CDATA[<p>I saw a post to the NodeJS mailing list the other day which went along the lines of </p>

<p><blockquote>
    I've created a simple prototype tool for re-factoring and re-organization of projects which heavily use require("./relativePath") .
  </blockquote></p>

<p>Without wishing to put the chap off from releasing OSS efforts (because this is nearly <em>always</em> an excellent idea) I responded with a sentence explaining why I thought this kind of thing was a bad idea. </p>

<p>I promised myself I'd write a blog entry with some loose thoughts in it too.</p>

<p>This is the classic example of a "tooling oriented fix" for a "problem of our own creation", after primarily making my living in the enterprise space where this sort of thing is rife I'm quite sensitive to such things when they arise when there is a better solution available.</p>

<p><em>If using relative paths in your JS project is painful, stop using relative paths in your JS projects</em></p>

<p><strong>Relative paths require cognitive effort</strong></p>

<p>When opening a project for the first time and encountering a large folder structure, I don't know where to begin. </p>

<p>Even when I'm told where to go, I then have to trawl through the dependencies manually to find the code I want to change. When I want to write tests, it's hard to work out where the files are that I want/need to bring in. </p>

<p>Compare this to a project which is comprised of modules, where each has a package.json which clearly describes where its git repo is, what its purpose is - and more importantly its dependencies. This is easy to understand and traverse and requires minimum new understanding.</p>

<p><strong>Relative paths lead to brittle coupling decisions</strong></p>

<p>If you're changing that code file, how do you know what is going to be impacted by that change? You don't - and this is why we get badly researched articles like <a href="http://techcrunch.com/2013/03/15/the-future-of-javascript/">this one</a> written about how hard JS is to maintain.</p>

<p>Better to make these dependencies explicit, and version them seperately so that upgrading to new versions of these dependencies is a conscious decision. Better still, applying <a href="http://semver.org/">a versioning strategy</a> so that breaking changes become obvious will make life much easier.</p>

<p><strong>Relative paths make tests harder to write</strong></p>

<pre><code>var sut = require('../src/company/lib/server/helpers/util.js')
</code></pre>

<p>Having a test suite that looks like the above over and over again is monstrous, you'll find yourself copying and pasting relative paths all over the suite and that'll in turn make you un-willing to re-factor or move things around for fear of breaking all the tests.</p>

<p>Compare this to instead a module-based approach where the tests we write for a module are simply covering that module. The effort required when decide to move things around is much smaller and we're not having to be dependenent on the organisation of files on your spinny disk or solid state storage.</p>

<p><strong>Relative paths are indicative of modules wanting to get out</strong></p>

<p>Take a look at your relative paths, look at commonly accessed files and consider that perhaps there is a module. Can you describe to me what that shared file does? What its purpose is? If so - you've passed the module test -get it in there.</p>

<p>If you can't tell me what that shared file does, then why does it exist? Is it just a "bag of stuff"? Don't create "bags of stuff", create "modules" with clearly defined purpose so the rest of us can have a clue of what is going on.</p>

<p><strong>So please, stop</strong></p>

<p>If you're not using some sort of package system to help you with your JavaScripts, then please start doing so. Preferably use NPM because it is one of the best designed package managers out there, but feel free to use Bower or something like that too, just stop presenting me with large codebases with piles of JS in them, it's costing you money to hire me and you don't want that money to be spent with me trying to work out how your folder structure works.</p>]]></description><link>http://codeofrob.com/entries/stop-using-relative-paths-in-your-javascripts.html</link><guid isPermaLink="true">http://codeofrob.com/entries/stop-using-relative-paths-in-your-javascripts.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Wed, 20 Mar 2013 09:30:00 GMT</pubDate></item></channel></rss>