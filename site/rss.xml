<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Rob Ashton's blog]]></title><description><![CDATA[Software development dumping ground]]></description><link>http://codeofrob.com</link><image><url>http://codeofrob.com/img/cover.jpg</url><title>Rob Ashton&apos;s blog</title><link>http://codeofrob.com</link></image><generator>NodeJS RSS Module</generator><lastBuildDate>Sat, 04 May 2013 13:12:01 GMT</lastBuildDate><atom:link href="http://feeds.feedburner.com/robashton" rel="self" type="application/rss+xml"/><item><title><![CDATA[Evented Github Adventure - Emitting Commits as their own events]]></title><description><![CDATA[<p>I'm <a href="/entries/less-abstract,-pumping-data-from-github-into-the-eventstore.html">ploughing all the events from Github into the EventStore</a> as is, but that doesn't mean they're instantly available for querying.</p>

<p>Lets say I want to write a few projections analysing the commits made across Github and performing some correlations off the back of that.</p>

<p>Well, currently there is no such thing as a CommitEvent - what we actually have is a PushEvent which contains a list of Commits in the payload like so</p>

<pre><code>{
   type: "PushEvent",
   repo: { // repo info },
   payload: {
     commits: [
      {
        sha: "etc",
        author: { //etc },
        message: "I am a banana"
      },
      {
        sha: "etc",
        author: { //etc },
        message: "My spoon is too big"
      },
      {
        sha: "etc",
        author: { //etc },
        message: "Tuesday's coming, did you bring your coat?"
      }
     ]
   }
}
</code></pre>

<p>Let's say I want to build up projections off the the stream of commits, in each of my projections I'd have to write the following code</p>

<pre><code>fromStream("github")
  .when({
    "$init": function(state, ev) {
      return {}
    },
    "PushEvent": function(state, ev) {
      for(var i = 0 ; i &lt; ev.body.payload.commits.length; i++) {
        var commit = ev.body.payload.commits[i]
        var repo = ev.body.repo

        // do stuff
      }
    }
  })
</code></pre>

<p>This doesn't cause a huge problem, but it is irritating having to do this for every projection and if I particularly cared about CPU it's also unnecessary work to be doing.</p>

<p>It would be much better if I could just have a stream of commits to read from when creating these projections.</p>

<pre><code>fromStream("github-commits")
  .when({
    "$init": function(state, ev) {

    },
    "Commit": function(state, ev) {
      var commit = ev.body.commit
      var repo = ev.body.repo

      // Do stuff
    }
  })
</code></pre>

<p>Well in fact we can, and that's a good place to use the 'emit' function. Let's say we have our original projection which loops over those commits:</p>

<pre><code>fromStream("github")
  .when({
    "$init": function(state, ev) {
      return {}
    },
    "PushEvent": function(state, ev) {
      for(var i = 0 ; i &lt; ev.body.payload.commits.length; i++) {
        var commit = ev.body.payload.commits[i]
        var repo = ev.body.repo
        emit("github-commits", "Commit", {
          commit: commit,
          repo: repo
        })
      }
    }
  })
</code></pre>

<p>And lo, we now have a new stream caled "github-commits", with a pile of "Commit" events with the commit and the repo information for that commit.</p>

<p><em>/streams/github-commits</em></p>

<pre><code>{
  title: "github-commits #2266",
  id: "http://127.0.0.1:2113/streams/github-commits/2266",
  updated: "2013-03-02T15:20:04.207363Z",
  author: {
    name: "EventStore"
  },
  summary: "Entry #2266",
  links: [
  {
    uri: "http://127.0.0.1:2113/streams/github-commits/2266",
    relation: "edit"
  },
  {
    uri: "http://127.0.0.1:2113/streams/github-commits/event/2266?format=text",
    type: "text/plain"
  },
  {
    uri: "http://127.0.0.1:2113/streams/github-commits/event/2266?format=json",
    relation: "alternate",
    type: "application/json"
  },
  {
    uri: "http://127.0.0.1:2113/streams/github-commits/event/2266?format=xml",
    relation: "alternate",
    type: "text/xml"
  }
  ]
},
</code></pre>

<p>Now, unlike "linkTo", this actually creates new events - as can be seen by the URIs in the above sample, and this decision comes with its own considerations but this is what I'll roll with for now and see where it gets me.</p>]]></description><link>http://codeofrob.com/entries/evented-github-adventure---emitting-commits-as-their-own-events.html</link><guid isPermaLink="true">http://codeofrob.com/entries/evented-github-adventure---emitting-commits-as-their-own-events.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Fri, 03 May 2013 09:30:00 GMT</pubDate></item><item><title><![CDATA[Less abstract, pumping data from Github into the EventStore]]></title><description><![CDATA[<p>It's all very well and good <a href="/entries/playing-with-the-eventstore.html">talking</a> <a href="/entries/pushing-data-into-streams-in-the-eventstore.html">events</a> <a href="/entries/basic-projections-in-the-eventstore.html">in</a> <a href="/entries/re-partitioning-streams-in-the-event-store-for-better-projections.html">the</a> <a href="/entries/creating-a-projection-per-stream-in-the-eventstore.html">abstract</a>, but there is only so long I can blather about ponies before I run out of the kind of data I can ask interesting questions about.</p>

<p>We turn to the <a href="http://developer.github.com/v3/activity/events/#list-public-events">Github Events API</a>, something I have a <a href="/entries/github-live.html">bit of experience</a> with for inspiration and start dumping all the events into the event store.</p>

<p>What does this look like?</p>

<p>Well, I'm interested in the public events stream, which can be polled up to 5000 times an hour (at current rates, it needs polling about every 10 seconds in order to keep up, so I'll not be able to get them all)</p>

<p>What this looks like</p>

<pre><code> var request = https.get(
 { host: 'api.github.com', path: '/events' + auth }, 
 function(res) {
    var data = ''
    res.on('data', function (chunk) {
      data += chunk
    });
    res.on('end', function() {
      processData(data)
    })
  })
  .on('error', function(e) {
    console.error(e)
  }).end()

  var processData = function(data) {
    var eventArray = JSON.parse(data)
    for(var i = eventArray.length-1 ; i &gt;= 0; i--) {
      processEvent(eventArray[i])
    }
  }
</code></pre>

<p>An event looks like this</p>

<pre><code>{
  id: "somelongid",
  type: "PushEvent",
  actor: { // info about the user },
  repo: { // info about the repo }
  payload: { // the event itself }
}
</code></pre>

<p>I'm going to be shoving these events 'as is' into the EventStore, and using their ids 'as is' too, this means I don't need to do any de-duping or anything like that.</p>

<p>Now, because of the kind of question I want to ask, it isn't enough for me to have the scant info about a repo that the event stream gives me (it looks like this)</p>

<pre><code>{
 "id": 3,
 "name": "octocat/Hello-World",
 "url": "https://api.github.com/repos/octocat/Hello-World"
}
</code></pre>

<p>So I'm going to augment each event with repo information (this is quite common in the eventing world, augmenting events with useful information for query purposes), and therefore my processEvent method looks something like this:</p>

<pre><code>function processEvent(ev) {
  if(ev.repo) {
    fetchRepoInfo(ev.repo.name, function(repo) {
      ev.repo = repo
      pushEventIntoEventStore(ev)
    })
  } else {
    pushEventIntoEventStore(ev)
  }
}
</code></pre>

<p>So, I'm not altering any of the events in any way, except by adding repo information to them, therefore if you're interested in the structure of any of the events I'm using you can easily look them up in the API.</p>

<p>By the time the code is readable there'll be some rate management code in there because I can't go looking up repo information for every single event and not go over the rate limit, but it's safe to say we'll be getting ~50% of the events from Github and that's a reasonable amount.</p>

<p>My script simply sits there running in the background and throws events into the event store and this little experiment is going to be about creating projections and asking questions of those events as we go along. Capiche? :)</p>]]></description><link>http://codeofrob.com/entries/less-abstract,-pumping-data-from-github-into-the-eventstore.html</link><guid isPermaLink="true">http://codeofrob.com/entries/less-abstract,-pumping-data-from-github-into-the-eventstore.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Thu, 02 May 2013 09:30:00 GMT</pubDate></item><item><title><![CDATA[Creating a projection per stream in the EventStore]]></title><description><![CDATA[<p><a href="/entries/re-partitioning-streams-in-the-event-store-for-better-projections.html">Now I have a stream per pony</a>, I want to create a projection per pony, but how do we do this?</p>

<p>Well, so far we've seen these two methods to get the events for our projection</p>

<ul>
<li>fromAny: Give us the events from all the streams</li>
<li>fromStream: Give us the event from a specific stream</li>
</ul>

<p>Well, now is the time to introduct another method we have at our disposal</p>

<ul>
<li>fromCategory: Run this for each "category"</li>
</ul>

<p>Well, what on earth IS a category? Turns out that the EventStore is quite clever and one of the default projections is hard at work looking at streams and categorising them.</p>

<p>I called my streams pony-PONYNAME for good reason, because this default projection will have gone "Hey, there is a dash in that stream, I'm going to create a category called pony, and each entry in that category is going to be a PONYNAME"</p>

<p>That leaves us with</p>

<pre><code>fromCategory('pony')
  .foreachStream()
  .when({
    "$init": function(state, ev) {
      return { count: 0 }
    },
    "PonyJumped": function(state, ev) {
      state.count++
    }
  })
</code></pre>

<p>For each stream in the category "pony", please run this projection code!</p>

<p><strong>Reading back the state</strong></p>

<p>We can now look at the state per pony by visiting the /state and passing in the partition we care about in the query string</p>

<p><em>/projection/jumpingponies2/state?partition=rainbowdash</em></p>

<pre><code>{
  count: 2000
}
</code></pre>

<p><em>/projection/jumpingponies2/state?partition=pinkiepie</em></p>

<pre><code>{
  count: 300
}
</code></pre>

<p><em>/projection/jumpingponies2/state?partition=derpy</em></p>

<pre><code>{
  count: 10
}
</code></pre>

<p><strong>NOTE</strong></p>

<p>It's at this point, people usually ask "How about giving me a list of ponies so I can look up the state for each of them", this is <em>not</em> what you use the EventStore for. </p>

<p>The list of ponies is something that should exist in your domain and be stored in a database (whether this be a document or relational database), and then used to look up values in the event store.</p>

<p>This could either be a fixed list in one of those stores, or you could run through the streams in the EventStore and build up that list as a read model in that external store. <em>This is the only time I'm going to mention this in this series :)</em></p>]]></description><link>http://codeofrob.com/entries/creating-a-projection-per-stream-in-the-eventstore.html</link><guid isPermaLink="true">http://codeofrob.com/entries/creating-a-projection-per-stream-in-the-eventstore.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Wed, 01 May 2013 09:30:00 GMT</pubDate></item><item><title><![CDATA[Re-partitioning streams in the Event Store for better projections]]></title><description><![CDATA[<p>We're able to do <a href="/entries/basic-projections-in-the-eventstore.html">aggregations of a stream's content by writing a projection</a>, and that's great - if we want to know about every jump every pony has performed over the entire stream. This is unlikely to be what we actually want though, people are narccisstic and ponies are no different, Rainbow Dash probably wants to know about just her jumping activity and Pinkie Pie wants to know about her own too, Derpy Hooves is probably too busy eating muffins to care, but we'll include her anyway.</p>

<ul>
<li>We've got a stream, which we have "all events for all ponies", we called it "ponies" because we're imaginative.</li>
<li>We've got a projection that can run over that stream and give us a total jump count for that stream</li>
<li>We want a projection for each pony that gives us the total jump count for that pony</li>
<li>We therefore want a stream for each pony, so we can generate a projection for that pony</li>
</ul>

<p>It turns out that this isn't too hard, let's look at how we do this:</p>

<p>Let's start with a basic projection over our ponies stream that doesn't do anything:</p>

<pre><code>fromStream('ponies')
.whenAny(function(state, ev) {

})
</code></pre>

<p>To re-iterate what we learned last time, this projection says "From the stream 'ponies', please invoke this callback for every event in the stream regardless of what the EventType is"</p>

<p>What we can actually do is create a new stream per pony, but link back to the original events from those new streams. </p>

<pre><code>fromStream('ponies')
.whenAny(function(state, ev) {
  linkTo('pony-' + ev.data.PonyName, ev)
})
</code></pre>

<p>linkTo takes two arguments</p>

<ul>
<li>The name of the stream to link the event to</li>
<li>The event itself</li>
</ul>

<p>For this projection, I "enable emits" beacuse that's what we're doing here</p>

<p>In our case, we're going to have a stream created for each pony, called pony-PONYNAME (so pony-rainbowdash, pony-derpyhooves, pony-pinkiepie), let's look at this to verify</p>

<p><em>/streams/pony-rainbowdash</em></p>

<pre><code>{
  title: "ponies #5502",
  id: "http://127.0.0.1:2113/streams/ponies/5502",
  updated: "2013-03-02T12:39:12.322785Z",
  author: {
    name: "EventStore"
  },
  summary: "Entry #5502",
  links: [
    {
      uri: "http://127.0.0.1:2113/streams/ponies/5502",
      relation: "edit"
    },
    {
      uri: "http://127.0.0.1:2113/streams/ponies/event/5502?format=text",
      type: "text/plain"
    },
    {
      uri: "http://127.0.0.1:2113/streams/ponies/event/5502?format=json",
      relation: "alternate",
      type: "application/json"
    },
    {
      uri: "http://127.0.0.1:2113/streams/ponies/event/5502?format=xml",
      relation: "alternate",
      type: "text/xml"
    }
  ]
}
</code></pre>

<p>This is just one of the events in that stream, but we can see an important point here, that <em>a new event was not created, the links are the original events from the original stream</em>. Cool!</p>

<p>If I look through the list of all streams, I can see that I now have a stream for each pony (in my case this is)</p>

<ul>
<li>/streams/pony-rainbowdash</li>
<li>/streams/pony-pinkiepie</li>
<li>/streams/pony-derpyhooves</li>
</ul>

<p>Now what I want to do is create a projection for each of these streams, so I can ask "how far has each of these ponies jumped", that's next :)</p>]]></description><link>http://codeofrob.com/entries/re-partitioning-streams-in-the-event-store-for-better-projections.html</link><guid isPermaLink="true">http://codeofrob.com/entries/re-partitioning-streams-in-the-event-store-for-better-projections.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Tue, 30 Apr 2013 09:30:00 GMT</pubDate></item><item><title><![CDATA[Basic projections in the EventStore]]></title><description><![CDATA[<p>Being able to <a href="/entries/pushing-data-into-streams-in-the-eventstore.html">shove events in and out</a> is great for our event sourced apps, but actually - if we have these streams, it's really useful to be able to consistently manipulate the events as they come in and either query those events or re-organise them so they can be queried.</p>

<p>To do this, we have the notion of projections, which are chunks of code that can be executed over a stream (with persisted state) as events are added to it. Now, in reality this isn't actually too different to what we'd be doing outside the event store when building up view models, and I foresee lots of bad things being done by people are the line between these different ways of reading streams are blurred and fought over.</p>

<p>I'm actually quite interested in these projections as a way of building up state for reports/charts, or re-partitioning into streams for different consumers - let's have a look how the most basic of these could work. </p>

<p>Let's say I've got a few events in the general structure of</p>

<pre><code>{
  EventType: "PonyJumped",
  Data: {
    Pony: "Derpy Hooves",
    Height: 10,
    Distance: 13
  }
}
</code></pre>

<p>and</p>

<pre><code>{
  EventType: "PonySpoke",
  Data: {
    Sentence: "This is the best day ever",
    Pony: "Pinkie Pie"
  }
}
</code></pre>

<p>And I'm putting all of these events into a single stream <em>ponies</em></p>

<p>Let's say that I've thrown a few hundred thousand of these events through the event store and I want to know something really basic, like how many times the ponies in my world have jumped since time began.</p>

<p>There is a Web UI available for managing projections in the event store (by default available at 127.0.0.1:2113). This is still subject to change though so I'll just be describing the ideas behind this concept.</p>

<p>There are some attributes of a projection that we can choose when creating a projection via HTTP or the UI</p>

<ul>
<li>Name: This is the name of the projection, I'll use this to look up the state</li>
<li>Source: This is the code to be executed</li>
<li>Emit Enabled: Projections can emit (or link) events if this is enabled</li>
<li>Enabled: Is this projection going to run?</li>
</ul>

<p>My options</p>

<ul>
<li>Name: "PonyJumpCount"</li>
<li>Source: TBC</li>
<li>Emit Enabled: Leaving this false (we'll cover usage of this later)</li>
<li>Enabled: Yes please!</li>
</ul>

<p>Now for the source, we'll start with the most basic projection which looks like this:</p>

<pre><code>fromAll()
  .whenAny(function(state,event) { 
     return null; 
  });
</code></pre>

<p>Basically, we have to select which streams we're going to be reading our events from, that "fromAll" bit means we're going to be reading from all of the streams, I'm going to go ahead and change that to "fromStream" and select our "ponies" stream.</p>

<pre><code>fromStream("ponies")
  .whenAny(function(state,event) { 
     return null; 
  });
</code></pre>

<p>How about that next bit "whenAny", well we've already matched which stream we want events from, well this is the bit we get to use to select which events from that stream we're interested in - "whenAny" just means "all the events in the stream".</p>

<p>I'm going to go ahead and change that to a when, which takes in a map of the events we're interested in and the callback to process the event with (pattern-matching on the EventType)</p>

<pre><code>fromStream("ponies")
  .when({
    "PonyJumped": function(state, event) {
      return null;
    })
</code></pre>

<p>Now for that callback - we have "state" and "event", the former being the state we're building up for this projection, and the latter being the event we're going to be adding to that state.</p>

<p>To begin with, we haven't actually got any state, but we can rectify that by chucking in an "$init" handler (anything starting with a dollar is something built in to the event store)</p>

<pre><code>fromStream("ponies")
  .when({
    $init: function() {
      return { count: 0 }
    },
    "PonyJumped": function(state, event) {
      return state
    }
  })
</code></pre>

<p>And now, the actual bit of code for building up our projection</p>

<pre><code>fromStream("ponies")
   .when({
        $init: function() {
           return { count: 0 }
        },
        "PonyJumped": function(state, event) {
          state.count += 1
        }
  })
</code></pre>

<p>If I hit save and navigate to</p>

<p><em>http://127.0.0.1:2113/projection/PonyJumpCount/state</em></p>

<pre><code>{
  count: 1337
}
</code></pre>

<p>I get some wonderful state.</p>

<p>Well, that was very basic, next time we'll look at how we could generate one of these projections for each pony we have in our world.</p>]]></description><link>http://codeofrob.com/entries/basic-projections-in-the-eventstore.html</link><guid isPermaLink="true">http://codeofrob.com/entries/basic-projections-in-the-eventstore.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Mon, 29 Apr 2013 09:30:00 GMT</pubDate></item><item><title><![CDATA[Pushing data into streams in the EventStore]]></title><description><![CDATA[<p>I'm <a href="/entries/playing-with-the-eventstore.html">playing with the EventStore</a> and I need to push some data into it in the form of streams.</p>

<p>What does this look like? Well I'm using NodeJS, and naturally that means using JSON and object literals:</p>

<p>So, if I have an event</p>

<pre><code>// An Event
{
  Data: {
    PonyName: "Rainbow Dash",
    TrampStamp: "Rainbow",
    Date: "January 2013"
  },
  EventType: "PonyBorn"
}
</code></pre>

<p>And I want to get this into a stream, well first I want to package it up</p>

<pre><code>// A package with the event in it
{
  CorrelationId: "something-i-know",
  ExpectedVersion: "last-version-i-knew-about",
  Events: [ ev ]
}
</code></pre>

<p>And serialise it</p>

<pre><code>var body = JSON.stringify(package)
</code></pre>

<p>I can POST it to the event store with the following code</p>

<pre><code>var req = http.request({
  host: "127.0.0.1",
  port: 2113,
  path: "/streams/ponies",
  method: "POST",
  headers: {
    "Accept": "application/json",
    "Content-Type": "application/json",
    "Content-Length": body.length
  }
}, function(res) {
  // Handle this
})

req.write(body)
req.end()
</code></pre>

<p>What do we notice about the data?</p>

<ul>
<li>We can supply a correlation id for our own convenience</li>
<li>We supply an expected version so our event can be rejected if things are not as they should be</li>
<li>We can send a collection of events to be committed all as one</li>
<li>EventType can be sent in alongside the event data</li>
</ul>

<p>And what do we notice about the request?</p>

<ul>
<li>We choose which stream to post to as part of the URL</li>
<li>We specify the content types we expect and are sending (because it can accept XML etc)</li>
</ul>

<p>What happens once I've done this?</p>

<p>Well, we'll see that I have a ponies stream</p>

<p><em>/streams</em></p>

<pre><code>{
  title: "ponies",
  uri: "http://127.0.0.1:2113/streams/ponies",
  accepts: [
    {
      type: "text/xml"
    },
    {
      type: "application/atom+xml"
    },
    {
      type: "application/json"
    },
    {
      type: "application/atom+x.json"
    }
  ]
},
</code></pre>

<p>And that if we go to this ponies stream via the URI specified we'll see</p>

<p><em>/streams/ponies</em></p>

<pre><code>[
  {
    title: "ponies #1",
    id: "http://127.0.0.1:2113/streams/ponies/1",
    updated: "2013-03-01T22:30:11.790066Z",
    author: {
      name: "EventStore"
    },
    summary: "Entry #1",
    links: [
      {
        uri: "http://127.0.0.1:2113/streams/ponies/1",
        relation: "edit"
      },
      {
        uri: "http://127.0.0.1:2113/streams/ponies/event/1?format=text",
        type: "text/plain"
      },
      {
        uri: "http://127.0.0.1:2113/streams/ponies/event/1?format=json",
        relation: "alternate",
        type: "application/json"
      },
      {
        uri: "http://127.0.0.1:2113/streams/ponies/event/1?format=xml",
        relation: "alternate",
        type: "text/xml"
      }
    ]
  },
  {
    title: "ponies #0",
    id: "http://127.0.0.1:2113/streams/ponies/0",
    updated: "2013-03-01T22:30:11.79004Z",
    author: {
      name: "EventStore"
    },
    summary: "Entry #0",
    links: [
      {
        uri: "http://127.0.0.1:2113/streams/ponies/0",
        relation: "edit"
      },
      {
        uri: "http://127.0.0.1:2113/streams/ponies/event/0?format=text",
        type: "text/plain"
      },
      {
        uri: "http://127.0.0.1:2113/streams/ponies/event/0?format=json",
        relation: "alternate",
        type: "application/json"
      },
      {
        uri: "http://127.0.0.1:2113/streams/ponies/event/0?format=xml",
        relation: "alternate",
        type: "text/xml"
      }
    ]
  }
]
</code></pre>

<p>We have two events, navigating to them we can see that one of them is for the creation of the stream</p>

<p><em>/streams/ponies/event/0?format=json</em></p>

<pre><code>{
  eventStreamId: "ponies",
  eventNumber: 0,
  eventType: "$stream-created-implicit",
  data: "",
  metadata: ""
}
</code></pre>

<p>And the other one is the event we pushed</p>

<p><em>/streams/ponies/event/1?format=json</em></p>

<pre><code>{
  eventStreamId: "ponies",
  eventNumber: 1,
  eventType: "PonyBorn",
  data: {
    PonyName: "Rainbow Dash",
    TrampStamp: "Rainbow",
    Date: "January 2013"
  },
  metadata: ""
}
</code></pre>

<p>Neato, I guess we notice a few things here then</p>

<ul>
<li>The stream doesn't contain the actual events, just links to the events</li>
<li>The stream is pageable, and contains the links to the pages (well, it's AtomPub)</li>
<li>Each event has its own unique uri, because events are immutable these can be cached by any intermdiate proxy</li>
</ul>

<p>And indeed, if we look at the header on a HTTP request for one of these events we'll see</p>

<pre><code>Cache-Control:max-age=31556926
</code></pre>

<p>That's cool, we've discovered that</p>

<ul>
<li>We can throw events into the event store with a default partitioning (the stream name specified)</li>
<li>We can get them back out again by paging through the links in that stream</li>
<li>Events are infinitely cacheable</li>
<li>Everything is AtomPub</li>
<li>Everything is easily navigable</li>
</ul>

<p>Now, if we were building a standard event sourced model we'd be able to page through these streams to build up our snapshots/viewmodels and that's all very neat and tidy and that would be the end of our story.</p>

<p>Next up however, it's more interesting to go and have a look at projections now, and see what questions we can ask of those streams in the event store itself.</p>]]></description><link>http://codeofrob.com/entries/pushing-data-into-streams-in-the-eventstore.html</link><guid isPermaLink="true">http://codeofrob.com/entries/pushing-data-into-streams-in-the-eventstore.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Fri, 26 Apr 2013 09:30:00 GMT</pubDate></item><item><title><![CDATA[Playing with the EventStore]]></title><description><![CDATA[<p>I pulled the <a href="http://geteventstore.com/">EventStore</a> out a while ago to play with, with the intention of making a cool Github InfoGraph type thing, it never quite materialised thanks to the rate limits imposed by Github, and then other stuff came up (like I've got a game engine I'm working on and I want to blog about!)</p>

<p>That said, I had some downtime this week in between engagements and decided to bring it up again and blog about some of the things I did with it and some of the questions we're able to ask with the projections feature (which is hitting a point of maturity now which it didn't have before).</p>

<p>Anyway, setting up the EventStore on my Debian install sorta looked like this</p>

<ul>
<li>Do a fresh build of Mono 3.0.5 (it won't work on the 2.10 that ships out of the box)</li>
<li>git clone the event store</li>
<li>checkout the projections branch (not out yet)</li>
<li>xbuild EventStore.sln</li>
<li>Build the v8 stuff</li>
<li>Set up LD<em>LIBRARY</em>PATH so the v8 stuff can be loaded from the .NET exe</li>
</ul>

<p>Coolio, so we'll assume that this is running throughout my little experiment and that I can access it on http://127.0.0.1:2113</p>

<p>Browsing to that URL, we can see a veritable playground of shinies, the most important for me are</p>

<ul>
<li>See All Streams</li>
<li>Projections</li>
</ul>

<p>Popping into the "See all Streams", we can see a big pile of json, what's cool about this is </p>

<ul>
<li>It's a pile of links</li>
<li>The links tell us what types are accepted</li>
<li>I can request this in various types as well (see the ?format=json) in this URL</li>
</ul>

<p>Basically, it's AtomPub, and AtomPub is used across the EventStore for interactions - which means no faffing around with custom formats or any of the crap associated with a lot of proprietary systems.</p>

<p>Anwyay, I haven't currently got any info in my event store so I guess I'll look at that next...</p>]]></description><link>http://codeofrob.com/entries/playing-with-the-eventstore.html</link><guid isPermaLink="true">http://codeofrob.com/entries/playing-with-the-eventstore.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Thu, 25 Apr 2013 09:30:00 GMT</pubDate></item><item><title><![CDATA[OMeta OData ODear - polishing it off]]></title><description><![CDATA[<p>Now I've gotten most of this work done, I left a few pieces of work outstanding and after review, I can make some of the OMeta cleaner and nicer. I also need to be a bit better about interpreting the various primitives in OData.</p>

<p>I've also got a more <a href="https://github.com/Page-/">qualified person</a> to review my OMeta as I go along and give me feedback on my work, so this is where I integrate a lot of that.</p>

<ul>
<li><a href="/entries/building-a-basic-json-parser-in-ometa.html">Learning OMeta through JSON</a></li>
<li><a href="/entries/building-an-odata-parser-in-ometa.html">Introduction to the OData Parser</a></li>
<li><a href="/entries/writing-an-odata-parser---starting-at-the-beginning.html">First steps in writing the OData Parser</a></li>
<li><a href="/entries/parsing-odata---nested-resource-paths.html">Nested resource paths in OData</a></li>
<li><a href="/entries/parsing-odata---service-operations.html">Service operations in OData</a></li>
<li><a href="/entries/the-odata-parser---applying-modifiers-to-our-query.html">Query options in OData</a></li>
<li><a href="/entries/paging-support-in-our-odata-parser.html">Paging support in OData</a></li>
<li><a href="/entries/our-odata-parser---looking-at-filterby.html">Filtering support in OData</a></li>
<li><a href="/entries/recursive-expression-parsing-in-our-odata-filter-parser.html">Recursive query support in OData</a></li>
<li><a href="/entries/these-are-not-the-results-you-are-looking-for---odata-parser.html">'Not' support for OData</a></li>
<li><a href="/entries/adding-arithmetic-operators-to-our-odata-parser.html">Arithmetic operator support in OData</a></li>
<li><a href="/entries/precedence-grouping,-you-first..-no-you-odata-parser.html">Precedence grouping in OData</a></li>
<li><a href="/entries/parsing-those-pesky-filtering-functions-in-odata.html">Filter query methods in OData</a></li>
<li><a href="/entries/the-final-odata-query-bits,-yes-were-nearly-there.html">The rest of OData</a></li>
</ul>

<h2>OMeta</h2>

<p><strong>Un-needed semantic actions</strong></p>

<p>In a few places in my OMeta I have expressions that look like this:</p>

<pre><code>(
  seq("allpages") -&gt; "allpages"
| seq("none") -&gt; "none"
)
</code></pre>

<p>This is quite wasteful and can be written much more simply as </p>

<pre><code>(
  seq("allpages") 
| seq("none")
)
</code></pre>

<p>This is because by default the last expression will be returned anyway</p>

<p>The same goes for this (ignoring that the Text primitive still needs some work)</p>

<pre><code>Text =
  &lt;    (   ~'\''
      (    '\\' anything
      |    letter
      )
    )*
  &gt;:text
  -&gt; text
</code></pre>

<p>Is much tidier if we get rid of the un-need semantic action because text will be returned anyway, and we can drop that named 'text' variable too.</p>

<pre><code>Text =
  &lt;    (   ~'\''
      (    '\\' anything
      |    letter
      )
    )*
  &gt;
</code></pre>

<p>And</p>

<pre><code>SelectOption =
  seq("$select=")
  (
    "*"                                 -&gt; '*' 
  | listOf(`PropertyPath, ','):properties  -&gt; { properties: properties }
  ):value -&gt; { name: "$select", value: value }
</code></pre>

<p>Is much better off without too</p>

<pre><code>SelectOption =
  seq("$select=")
  (
    "*"
  | listOf(`PropertyPath, ','):properties  -&gt; { properties: properties }
  ):value -&gt; { name: "$select", value: value }
</code></pre>

<p><strong>Stop repeating yourself!</strong></p>

<p>OMeta uses memoisation so this isn't a big deal, but repeating yourself is annoying anyway and we can be far more expressive if we think about commonly matches constructs in our code.</p>

<pre><code>(
  seq(" asc") -&gt; "asc"
| seq(" desc") -&gt; "desc"
)?:order
</code></pre>

<p>Here I'm looking for a sequence of characters with 'space' 'asc' 'space' and this would be far better written as</p>

<pre><code>spaces
(
  seq("asc")
| seq("desc")
| -&gt; 'desc'
):order
</code></pre>

<p>And to boot I've added in the default, which is 'desc' so I don't need that optional '?' anymore.</p>

<p>And how about this little one?</p>

<pre><code>listOf(`PropertyPath, ',')
</code></pre>

<p>I use that in quite a few places in the code, better split it off into its own rule</p>

<pre><code>PropertyPathList = 
  listOf(`PropertyPath, ',')
</code></pre>

<p>And use that around the place instead!</p>

<p><strong>Un-needed brackets</strong></p>

<pre><code>  PathSegment:model 
  (
    '?'
    ( listOf(`QueryOption, '&amp;'):options
    )
  )?
</code></pre>

<p>I do this in a few places, and while it causes no harm, OMeta is hard enough to read to the un-initiated without throwing brackets in all of the place</p>

<pre><code>  PathSegment:model 
  (
    '?'
    listOf(`QueryOption, '&amp;'):options
  )?
</code></pre>

<p>Not rocket science!</p>

<p><strong>Custom matching methods</strong></p>

<p>Admittedly I hacked this together in a rum-bar at 10pm, but I have this floating around in the code for dealing with <a href="/entries/parsing-those-pesky-filtering-functions-in-odata.html">filter methods</a></p>

<pre><code>SingleArgMethodCall :name =
  seq(name) 
  '(' 
  spaces 
  FilterByExpression:one 
  spaces
  ')' -&gt; { args: [ one ], method: name }
,

TwoArgMethodCall :name = 
  seq(name)
  '(' 
  spaces 
  FilterByExpression:one 
  spaces 
  ',' 
  spaces 
  FilterByExpression:two 
  spaces 
  ')' -&gt; { args: [ one, two ], method: name }
, 

ThreeArgMethodCall :name = 
  seq(name)
  '(' 
  spaces 
  FilterByExpression:one 
  spaces 
  ',' 
  spaces 
  FilterByExpression:two 
  spaces 
  ','
  spaces
  FilterByExpression:three 
  spaces 
  ')' -&gt; { args: [ one, two, three ], method: name }
, 
</code></pre>

<p>This is still better than doing the above individually for <em>every single supported method</em>, but it would be nice if we could do</p>

<pre><code>MethodCall(name, arity)
</code></pre>

<p>Instead of having three different expressions in a non-expandable manner</p>

<p>Well, first off - the beginning of this will looke lik</p>

<pre><code>MethodCall :name :arity =
  seq(name)
  '('
    numberOf(`FilterByExpression, arity):args
  ')' -&gt; { args: args, method: name }
,
</code></pre>

<p>Except there is no function called numberOf.</p>

<p>Extending our OMeta parser with custom functions is really easy though.</p>

<pre><code>ODataParser.numberOf = function(rule, count, seperator) {
  var ret = [];
  for(var i = 1; i &lt; count; i++) {
    ret.push(this._apply(rule));
    this._apply("spaces");
    this._applyWithArgs('exactly', seperator)
    this._apply("spaces");
  }
  ret.push(this._apply(rule));
  return ret;
}
</code></pre>

<p>These '_apply' methods are simply what the rules are converted into when the OMeta is transpiled into JS, and we're skipping that bit and patching our parser with the raw JS. Simples!</p>

<h2>OData, ODear</h2>

<p>Well, I skipped a few steps here certainly - especially with regard to the following rules:</p>

<pre><code>Number = &lt;digit+&gt;:d -&gt; parseInt(d, 10),
  Number = &lt;digit+&gt;:d -&gt; parseInt(d, 10),
  Text =
    &lt;    (   ~'\''
        (    '\\' anything
        |    letter
        )
      )*
    &gt;:text
  ,

  QuotedText =
    '\''
    Text:t 
    '\'' -&gt; t
  ,
Text =
  &lt;    (   ~'\''
      (    '\\' anything
      |    letter
      )
    )*
  &gt;:text
,
</code></pre>

<p>and</p>

<pre><code>ResourcePart =
  &lt;    (   letter
    |    '_'
    )+
  &gt;:resourcePart
  -&gt; resourcePart.replace(new RegExp('_', 'g'), ' ')
,

ResourceName =
  &lt;    ResourcePart
    (    '-'
      ResourcePart
    )*
  &gt;
</code></pre>

<p>These are our primitives in the OData space, everything else is built up off of them and I've been a bad person and not done them properly. (If anybody has bothered reading all the way up to here, you probably thought this at the time and maybe even commented about it)</p>

<p><strong>Text and QuotedText</strong></p>

<p>Just what <em>is</em> Text? </p>

<p><em>As part of the query string</em></p>

<pre><code>OperationParam = 
  Text:name '=' Text:value -&gt; { name: name, value: value }
</code></pre>

<p><em>And inside quotes as a string literal</em></p>

<pre><code>QuotedText =
  '\''
  Text:t 
  '\'' -&gt; t
,
</code></pre>

<p><em>What are the rules?</em></p>

<p>Well, if it's part of the query string, let's say it's the name of a parameter, it can be anything at all (except reserved characters from the Uri - these should be encoded). To solve this we need to read the <a href="http://tools.ietf.org/html/rfc3986">RFC</a></p>

<pre><code> reserved    = gen-delims / sub-delims
 gen-delims  = ":" / "/" / "?" / "#" / "[" / "]" / "@"
 sub-delims  = "!" / "$" / "&amp;" / "'" / "(" / ")"
                         / "*" / "+" / "," / ";" / "="
</code></pre>

<p>We should recognise most of these, although some of these are explicitly allowed in some uri schemes and according to this RFC that's okay. </p>

<p>Still, an implementation of this can look something like:</p>

<pre><code>ReservedUriComponent  =
  GenDelim
| SubDelim
,

GenDelim = 
  ":" | "/" | "?" | "#" | "[" | "]" | "@"
,

SubDelim = 
  "!" | '$' | '*' | "'" | "&amp;" | "(" | ")" | "+" | "," | ";" | "="
,

Text =
  &lt;
    ~ReservedUriComponent*
    anything
  &gt;
,
</code></pre>

<p>What I'll do, is explicitly deny all of these characters except in cases where I explicitly allow them (for example, the dollar symbol is allowed in built-in query params, brackets are allowed in expressions, quotes are allowed to denote string literals, etc)</p>

<p>I can use this rule safely for quoted text as that rule explicitly allows quoted text:</p>

<pre><code>QuotedText =
  '\''
  Text:t 
  '\'' -&gt; t
</code></pre>

<p><strong>Resource paths</strong></p>

<p>Same thing now goes here, and I can say that each part of a resource path is a UriComponent, explicitly disallowing spaces, separated by a '/', so</p>

<pre><code>ResourceName =
  &lt;(    
    ~(ReservedUriComponent | ' ')
    anything
  )+
  &gt;:resourceName
</code></pre>

<p>Much happier about all of this.</p>

<p><strong>Decoding as we go</strong></p>

<p>If somebody does give us some text that looks like this</p>

<pre><code>foo='hello%20world'
</code></pre>

<p>It would be nice if it was decoded for output</p>

<pre><code>Text =
  &lt;
   (~ReservedUriComponent
   anything)*
  &gt;:text -&gt; decodeURIComponent(text)
,
</code></pre>

<p>We can indeed call arbitrary JS methods in our semantic output, good for us.</p>

<p>We'll do the same for resource names too</p>

<pre><code>ResourceName =
  &lt;(    
    ~(ReservedUriComponent | ' ')
    anything
  )+
  &gt;:resourceName -&gt; decodeURIComponent(resourceName)
</code></pre>

<p>I think if I was to go and do some of this again, I'd have been explicit about Uri conformance from the start, but it hasn't caused too much damage so we're okay.</p>

<p><strong>Supporting further primitives</strong></p>

<p>At the moment we can parse integers with</p>

<pre><code>Number = &lt;digit+&gt;:d -&gt; parseInt(d, 10)
</code></pre>

<p>But this is only half the story, we actually need to explicitly support decimals too</p>

<pre><code>Number = Decimal | Integer
,

Decimal = 
  &lt;
    digit+
    '.'
    digit+
  &gt;:d     -&gt; new Number(d)
, 

Integer = &lt;digit+&gt;:d -&gt; parseInt(d, 10)
,
</code></pre>

<p><strong>Semantic output</strong></p>

<p>I'm now much happier that we have our bases covered with the types that we support, and that I'm not doing anything nefarious with OMeta, that leaves me with a final tidy-up task.</p>

<p>In some cases, we're outputting to an array that states 'this is what you have, so now you know how to interpret it', this is quite a standard way of doing things in OMeta and particularly in the expression parsing space.</p>

<p>By outputting to an array in this manner, it becomes very easy to write a further OMeta processing step to convert the output of the OMeta parsing step into another format (compilation).</p>

<p>This is useful for say, generating SQL based on the model that these chaps have defined in SBVR.</p>

<p>Let's look at a tangible example where I've gotten this weird:</p>

<pre><code>SelectOption =
  seq("$select=")
  (
    "*"                                 -&gt; '*' 
  | PropertyPathList:properties  -&gt; { properties: properties }
  ):value -&gt; { name: "$select", value: value }
,
</code></pre>

<p>In one case, our semantic action is to return a string containing a single character *, and other case I return an object literal with a list of properties in it.</p>

<p>I kinda want to go through and sort this out, but without using it in anger (say, for generating SQL), it's hard to say what a useful model will look like.</p>

<p>I've also made some mistakes in that I didn't refactor my tests as I went to eliminate duplication, so they're a bit coupled to the structure of the model.</p>

<p>I've decided that as I only have a day left at the client, that the best thing I can do at this point is raise my hands in the air and point out very publicly that:</p>

<ul>
<li>The tests are brittle <em>because</em> and this is how you'd improve them</li>
<li>The model probably isn't that easy to consume, and will need changing, which will mean the tests need changing, <em>sorry</em></li>
</ul>

<p>With this said and done, I've decided the final bit of work I can do is to run some fuzzy testing against the parser and start trying to make it <em>really</em> complete, as this is a harder problem. (and maybe I can refactor the tests as I do this, so I only leave one problem for them to sort out)</p>

<p><strong>Fuzzy testing</strong></p>

<p>So I found a great tool (or at least something that sounds like a great tool), which <a href="http://www.quut.com/abnfgen/">generates output based on an ABNF</a>, and OData conveniently has an <a href="http://www.odata.org/media/30002/OData%20ABNF.html">ABNF specified for it</a> so let's go!</p>

<p>What I'll do to get started is download and compile the abnfgen package, and run a single test case to make sure that this crazy idea is going to work, then I'll automate it and tell it to dump failed cases to a list so I can re-run them and work out why they've failed.</p>

<p><em>edit</em></p>

<p>Scratch that, the ABNF is incomplete and buggy and crap, what is the actual point, onto making something pretty instead...</p>

<p><strong>Hooking it up to the editor</strong></p>

<p>Because one of the main reasons for using OMeta (other than "it's what they use for most parsing already"), is the support for it in the editor that they use across the organisation.</p>

<p>Hooking it up was a simple matter of grabbing some code already written to run OMeta against a third party editor, and adding support to the parser for this.</p>

<p>To do this, I just have to add a method to my parser like so:</p>

<pre><code>ODataParser._enableTokens = function() {
  OMeta._enableTokens.call(this, ['Text', 'ResourceName', 'Number', 'RecognisedOption', 'FilterAndOperand', 'FilterByOperand', 'FilterRecognisedMathOperand']);
};
</code></pre>

<p>You'll notice if you're observant, that I've added a few more named types here, that's because otherwise I had no way of matching key words and therefore colouring them separately.</p>

<p>Instead of</p>

<pre><code>seq("add")
</code></pre>

<p>I now have</p>

<pre><code>FilterRecognisedMathOperand("add")
,

FilterRecognisedMathOperand :name = 
  seq(name)
</code></pre>

<p>That's about the only type of change I had to make to support the following glory:</p>

<p><img src="/img/parse_output.png" alt="Highlighted output in a text area from OData input" title="Parse output"/></p>

<p>Mission accomplished, now onto my next client...</p>]]></description><link>http://codeofrob.com/entries/ometa-odata-odear---polishing-it-off.html</link><guid isPermaLink="true">http://codeofrob.com/entries/ometa-odata-odear---polishing-it-off.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Tue, 23 Apr 2013 09:30:00 GMT</pubDate></item><item><title><![CDATA[The final OData query bits, yes we're nearly there]]></title><description><![CDATA[<p>So yes, we <strong>are</strong> nearly there, in fact we only have a few query options remaining, which I'll cover entirely here because they're all pretty miniscule.</p>

<ul>
<li><a href="/entries/building-a-basic-json-parser-in-ometa.html">Learning OMeta through JSON</a></li>
<li><a href="/entries/building-an-odata-parser-in-ometa.html">Introduction to the OData Parser</a></li>
<li><a href="/entries/writing-an-odata-parser---starting-at-the-beginning.html">First steps in writing the OData Parser</a></li>
<li><a href="/entries/parsing-odata---nested-resource-paths.html">Nested resource paths in OData</a></li>
<li><a href="/entries/parsing-odata---service-operations.html">Service operations in OData</a></li>
<li><a href="/entries/the-odata-parser---applying-modifiers-to-our-query.html">Query options in OData</a></li>
<li><a href="/entries/paging-support-in-our-odata-parser.html">Paging support in OData</a></li>
<li><a href="/entries/our-odata-parser---looking-at-filterby.html">Filtering support in OData</a></li>
<li><a href="/entries/recursive-expression-parsing-in-our-odata-filter-parser.html">Recursive query support in OData</a></li>
<li><a href="/entries/these-are-not-the-results-you-are-looking-for---odata-parser.html">'Not' support for OData</a></li>
<li><a href="/entries/adding-arithmetic-operators-to-our-odata-parser.html">Arithmetic operator support in OData</a></li>
<li><a href="/entries/precedence-grouping,-you-first..-no-you-odata-parser.html">Precedence grouping in OData</a></li>
<li><a href="/entries/parsing-those-pesky-filtering-functions-in-odata.html">Filter query methods in OData</a></li>
</ul>

<p><strong>Expand</strong></p>

<p>Expand allows the expansion of a particular property path in OData, like so</p>

<p><em>Expand the path Products/Suppliers</em></p>

<pre><code>/Categories?$expand=Products/Suppliers
</code></pre>

<p><em>Expand the path Suppliers AND expand the path Products</em></p>

<pre><code>/Categories?$expand=Suppliers,Products
</code></pre>

<p>So this is quite easy, $expand expects a list of ResourcePath, separated by a comma.</p>

<p>I'll not show the tests for this, you can assume I have some though, with the appropriate data appearing on the model..</p>

<pre><code>ExpandOption = 
  seq("$expand=")
  listOf(`PropertyPath, ','):properties -&gt; { name: "$expand", value: { properties: properties }}
,
</code></pre>

<p>Doesn't take a genius to work that one out does it :)</p>

<p><strong>Format</strong></p>

<p>This one is a doozy, the docs pretty much say it accepts</p>

<ul>
<li>application/atom+xml</li>
<li>application/xml</li>
<li>application/json</li>
<li>Any other valid IANA content type</li>
</ul>

<p>So what we're saying here is that we'll parse any content type, what I'll do is just parse the general pattern to make sure it doesn't contain garbage and leave it at that.</p>

<pre><code>FormatOption = 
  seq("$format=")
  ContentType:type -&gt; { name: "$format", value: type }
,

ContentType = 
  &lt; letter+
    '/' 
    letter+
    (
      '+' letter+
    )?
  &gt;
</code></pre>

<p>There are probably more rules than that but it's easily improved later</p>

<p><strong>Select</strong></p>

<p>Select tells us what is going to be brought back from a query, this can either be a property path, a collection of property paths or an asterisk.</p>

<p>An asterisk means bring back EVERYTHING. Nothing special.</p>

<pre><code>SelectOption =
  seq("$select=")
  (
    "*"                                 -&gt; '*' 
  | listOf(`PropertyPath, ','):properties  -&gt; { properties: properties }
  ):value -&gt; { name: "$select", value: value }
,
</code></pre>

<p><strong>Highlighting a problem or three</strong></p>

<p>That's pretty much the entire spec sorted out, and we have a few tidy ups on our hand</p>

<ul>
<li>The model we're building isn't meaningful enough</li>
<li>I've done some messy OMeta, it needs tidying</li>
<li>I'm not handling primitive types properly (ResourceNames, ResourceComponents, Numbers etc)</li>
</ul>

<p>I'll sort all these out in the next entry (I imagine that there will have been some comments made about these already in the future... in the past now, I wrote all this a month ago after all) and then we'll be finished and onto something new.</p>]]></description><link>http://codeofrob.com/entries/the-final-odata-query-bits,-yes-were-nearly-there.html</link><guid isPermaLink="true">http://codeofrob.com/entries/the-final-odata-query-bits,-yes-were-nearly-there.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Mon, 22 Apr 2013 09:30:00 GMT</pubDate></item><item><title><![CDATA[Parsing those pesky filtering functions in OData]]></title><description><![CDATA[<p>The final bit of our $filter feature is the ability to invoke a special function and compare the result of that to the rest of an expression.</p>

<p>Again a reminder of where we are so far:</p>

<ul>
<li><a href="/entries/building-a-basic-json-parser-in-ometa.html">Learning OMeta through JSON</a></li>
<li><a href="/entries/building-an-odata-parser-in-ometa.html">Introduction to the OData Parser</a></li>
<li><a href="/entries/writing-an-odata-parser---starting-at-the-beginning.html">First steps in writing the OData Parser</a></li>
<li><a href="/entries/parsing-odata---nested-resource-paths.html">Nested resource paths in OData</a></li>
<li><a href="/entries/parsing-odata---service-operations.html">Service operations in OData</a></li>
<li><a href="/entries/the-odata-parser---applying-modifiers-to-our-query.html">Query options in OData</a></li>
<li><a href="/entries/paging-support-in-our-odata-parser.html">Paging support in OData</a></li>
<li><a href="/entries/our-odata-parser---looking-at-filterby.html">Filtering support in OData</a></li>
<li><a href="/entries/recursive-expression-parsing-in-our-odata-filter-parser.html">Recursive query support in OData</a></li>
<li><a href="/entries/these-are-not-the-results-you-are-looking-for---odata-parser.html">'Not' support for OData</a></li>
<li><a href="/entries/adding-arithmetic-operators-to-our-odata-parser.html">Arithmetic operator support in OData</a></li>
<li><a href="/entries/precedence-grouping,-you-first..-no-you-odata-parser.html">Precedence grouping in OData</a></li>
</ul>

<p><strong>Function calls look like this</strong></p>

<pre><code>/Customers?$filter=substringof('Alfreds', CompanyName) eq true
</code></pre>

<p>In other words, they're a special piece of the expression which can take a list of expressions separated by commas</p>

<p>I could hack this and just allow any function call, or I can explicitly name them all - which I'll do because it'll help with the highlighting in the editor that'll use this parser.</p>

<p>I'll do the first one here, and then go and do the rest in a similar fashion because they're just the same thing over and over again!</p>

<p>Our test for 'substringof'</p>

<pre><code>test("/resource?$filterby=substringof('alfred', Product) eq 'cake'", "OData", function(result) {
  it("A filter should be present", function() {
     assert.notEqual(result.options.$filterby, null)
  })
  it("Filter should be an instance of 'eq'", function() {
     assert.equal(result.options.$filterby[0], "eq")
  })
  it("lhs should be a function call", function() {
     assert.equal(result.options.$filterby[1][0], "call")
  })
  it("lhs should be substringof with correct args", function() {
     assert.equal(result.options.$filterby[1][1].method, 'substringof')
     assert.equal(result.options.$filterby[1][1].args[0], 'alfred')
     assert.equal(result.options.$filterby[1][1].args[1].name, 'Product')
  })
  it("rhs should be cake", function() {
     assert.equal(result.options.$filterby[2], "cake")
  }) 
})
</code></pre>

<p>This kinda thing will do, and getting the method out is a simple  matter of adding the MethodExpression to the values possible in an expression:</p>

<pre><code>FilterByValue = 
  FilterMethodCallExpression
| FilterNegateExpression
| Number
| QuotedText
| PropertyPath
| GroupedPrecedenceExpression
,
</code></pre>

<p>Now, it is tempting to be lazy and just write a  generic method recogniser with variable lists of args, but we're building for highlighting so it would be nice to know what the recognised methods are, and what args they expect, so what I'll do is this</p>

<pre><code>FilterMethodCallExpression = 
  (
    FilterSubstringOf
  | OtherMethod
  | AnotherMethod
  ) -&gt; [ "call", methodcall ]
,
</code></pre>

<p>And write a definition for each method (tedious, but I'll automate a pile of that with VIM macros)</p>

<pre><code>FilterSubstringOf = 
  seq('substringof'):method 
  '(' 
  spaces 
  FilterByExpression:one 
  spaces 
  ',' 
  spaces 
  FilterByExpression:two 
  spaces 
  ')' -&gt; { args: [ one, two ], method: method }
</code></pre>

<p>And they'll all look like that.</p>

<p>With this done, $filter is now fully supported and I can get on with mopping up the final recognised pieces of OData. I'll try and do that all in a single post.</p>]]></description><link>http://codeofrob.com/entries/parsing-those-pesky-filtering-functions-in-odata.html</link><guid isPermaLink="true">http://codeofrob.com/entries/parsing-those-pesky-filtering-functions-in-odata.html</guid><dc:creator><![CDATA[Rob Ashton]]></dc:creator><pubDate>Fri, 19 Apr 2013 09:30:00 GMT</pubDate></item></channel></rss>